{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TpmFfXsQ0dYI"
   },
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <td><img src=\"./imagenes/Macc.png\" width=\"400\"/></td>\n",
    "        <td>&nbsp;</td>\n",
    "        <td>\n",
    "            <h1 style=\"color:blue;text-align:left\">Inteligencia Artificial</h1></td>\n",
    "        <td>\n",
    "            <table><tr>\n",
    "            <tp><p style=\"font-size:150%;text-align:center\">Notebook 8</p></tp>\n",
    "            <tp><p style=\"font-size:150%;text-align:center\">El mundo del Wumpus</p></tp>\n",
    "            </tr></table>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V3SkDSWJ0dYJ"
   },
   "source": [
    "# Objetivo <a class=\"anchor\" id=\"inicio\"></a>\n",
    "\n",
    "Vamos a entrar de lleno en el enfoque basado en agentes de la Inteligencia Artificial. Para comprender mejor este enfoque debemos tomar la perspectiva de un agente que tiene que superar un reto en un minimundo. En este notebook, el minimundo es el mundo del Wumpus y uno de los objetivos de este notebook es familiarizarnos con dicho entorno. Adicionalmente, implementaremos un programa de agente muy sencillo (un agente de reflejo simple), el cual nos servirá para darnos cuenta de qué otros recursos debe tener a su disposición el agente para cumplir la meta de encontrar el oro en la caverna del Wumpus (sin morir en el intento). Finalizaremos haciendo una representación de algunas de las reglas de este mundo mediante la lógica proposicional.\n",
    "\n",
    "Adaptado de Russell & Norvig (2016), cap. 7."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5HnQ_gA70dYL"
   },
   "source": [
    "# Secciones\n",
    "\n",
    "En este notebook desarrollaremos los siguientes aspectos del problema:\n",
    "\n",
    "* [El mundo del Wumpus.](#wumpus)\n",
    "* [Agente de reflejo simple.](#simple-reflex)\n",
    "* [Representando el mundo mediante lógica proposicional.](#representacion)\n",
    "* [Agente basado en objetivos.](#goalba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S4x5lJfd0dYM"
   },
   "source": [
    "# El mundo del Wumpus <a class=\"anchor\" id=\"wumpus\"></a>\n",
    "\n",
    "([Volver al inicio](#inicio))\n",
    "\n",
    "El siguiente problema se conoce como *El mundo del Wumpus* (Yob, 1975). Imagine una caverna muy oscura, representada por una rejilla de $4\\times 4$ rodeada de muros. Un agente (nuestro héroe de la historia) puede entrar y salir de la caberna por la casilla (0,0) y puede percibir solamente lo que hay en cada casilla en la que se encuentre. En la caverna hay pozos muy profundos; si cae en uno de ellos, morirá. Lo peor de todo es que hay un mounstro, conocido como el Wumpus, el cual se comerá vivo al agente si éste entra a su casilla. ¿Por qué el agente entraría a un lugar como este? ¡Porque en alguna casilla de la cueva hay un montón de oro!\n",
    "\n",
    "<img src=\"./imagenes/ejemplo.png\" width=\"400\">\n",
    "\n",
    "Las siguientes son las reglas que gobiernan el mundo:\n",
    "\n",
    "* En cualquier casilla adyacente (no diagonalmente) a un pozo se percibe una brisa; \n",
    "* En cualquier casilla adyacente (no diagonalmente) al Wumpus se percibe un hedor; \n",
    "* En la casilla donde se encuentra el oro se percibe un brillo. \n",
    "* El wumpus nunca se mueve de su casilla.\n",
    "\n",
    "Finalmente, el agente tiene un arco y solo una flecha, con la cual puede matar al Wumpus. Cuando el agente dispara la flecha, ésta seguirá en la misma dirección del agente hasta golpear un muro o clavarse en el Wumpus, quien morirá arrojando un desgarrador grito \"Aaaaaaarrrrgghhhhh\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P60dU8Mg0dYO"
   },
   "source": [
    "**Ejercicio 1:**\n",
    "\n",
    "De acuerdo con la formulación de entornos hecha al comienzo del curso, ¿cuáles características considera usted que tiene este problema?\n",
    "\n",
    "**Ayuda:** Puede usar el comando `$\\checkmark$` para poner un chulito en la opción que desee marcar. \n",
    "\n",
    "| Opción 1 | Opción 2 |\n",
    "| :---: | :---: |\n",
    "| Completamente observable | Parcialmente observable|\n",
    "| Agente único | Multiagente |\n",
    "| Determinista | Estocástico |\n",
    "| Episódico    | secuencial  |\n",
    "| Estático     | dinámico    |\n",
    "| Discreto     | continuo    |\n",
    "| Conocido     | desconocido |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vL49lY0r0dYP"
   },
   "source": [
    "La **definición formal del entorno** se hace con base en la definición de las siguientes características:\n",
    "\n",
    "* **Entorno**: Una cueva representada por una rejilla $4\\times 4$ bordeada por muros. El agente siempre comienza en (0, 0) mirando a la derecha. La ubicación del Wumpus se escoge arbitrariamente de manera uniforme en casillas distintas a la inicial. Cualquier casilla distinta de la inicial puede ser un pozo con probabilidad 0.2. El oro puede estar en cualquier casilla, con probabilidad uniforme.\n",
    "\n",
    "* **Actuadores**: El héroe puede moverse `adelante` por una casilla (no es posible moverse adelante cuando hay un muro), `voltearIzquierda` por 90º, o `voltearDerecha` por 90º. Es posible `agarrar` el oro cuando este está en la casilla ocupada por el héroe. También puede `disparar` la flecha en la dirección en que está mirando, la cual seguirá en linea recta hasta golpear un muro. Finalmente, el agente puede `salir` de la cueva, pero solo desde la casilla inicial.\n",
    "\n",
    "* **Sensores**: El héroe percibe un `hedor` cuando llega a la casilla donde está el Wumpus o cuando llega a una de las casillas adyacentes (no diagonalmente). En las casillas adyacentes a un pozo, percibe una `brisa`. En el cuadro donde está el oro, percibe un `brillo`. Cuando se topa con un muro, percibe un `batacazo`. Finalmente, si el Wumpus muere, el heroe percibe un `grito` desde cualquier casilla.\n",
    "\n",
    "* **Medida de desempeño**: +1000 por salir de la cueva con el oro; -1000 por caer en un pozo o ser comido por el Wumpus; -1 por cada acción y -10 por usar la flecha. El juego termina cuando el heroe muere o sale de la cueva."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ESao4G9n0dYP"
   },
   "source": [
    "\n",
    "**Implementación del entorno**\n",
    "\n",
    "Implementaremos el mundo del Wumpus mediante una clase en Python.\n",
    "\n",
    "Primero cargamos librerías:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "73kSrhUo0dYQ"
   },
   "outputs": [],
   "source": [
    "from logica import *\n",
    "from entornos import *\n",
    "from agentes import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicializamos el mundo y percibimos lo que hay en la primera casilla:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = Wumpus(wumpus=(3,3), oro=(2,2), pozos=[(1,0), (3,1)])\n",
    "W.pintar_casilla()\n",
    "agente = Agente()\n",
    "agente.perceptos = W.para_sentidos()\n",
    "print(agente.perceptos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un paso arriesgado en la oscuridad:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W.transicion('voltearIzquierda')\n",
    "W.transicion('adelante')\n",
    "W.pintar_casilla()\n",
    "agente.perceptos = W.para_sentidos()\n",
    "print(agente.perceptos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 2:**\n",
    "\n",
    "Escriba el código para que desde la casilla a la que llegó en la ejecución de la celda anterior (que es la (0,1)) el héroe avance dos casillas a la derecha y una arriba, percibiendo el entorno a cada paso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agente de reflejo simple <a class=\"anchor\" id=\"simple-reflex\"></a>\n",
    "\n",
    "([Volver al inicio](#inicio))\n",
    "\n",
    "Ya que tenemos alguna familiaridad con el mundo del Wumpus, vamos a implementar nuestro primer agente que va a enfrentarse al reto de buscar el oro en esa aterradora caverna. Este agente será de reflejo simple:\n",
    "\n",
    "<img src=\"./imagenes/env-simple-reflex.png\" width=\"400\">\n",
    "\n",
    "Las reglas de condición-acción que implementaremos serán las siguientes:\n",
    "\n",
    "* Si percibe el brillo, tomar el oro.\n",
    "* Si siente un batacazo, escoja aleatoriamente si voltearse a la derecha, izquerda o regresarse y avanzar una casilla.\n",
    "* Si no percibe ni brisa ni hedor, avanzar una casilla.\n",
    "* Si percibe un hedor o una brisa, devolverse.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import choice\n",
    "\n",
    "# perceptos[0]  =>  hedor\n",
    "# perceptos[1]  =>  brisa\n",
    "# perceptos[2]  =>  brillo\n",
    "# perceptos[3]  =>  batacazo\n",
    "# perceptos[4]  =>  grito\n",
    "reglas = {\n",
    "    # Si percibe el brillo, tomar el oro.\n",
    "    'self.perceptos[2]': \"['agarrar']\",\n",
    "    # Si siente un batacazo, escoja aleatoriamente si voltearse \n",
    "    # a la derecha, izquerda o regresarse y avanzar una casilla.\n",
    "    'self.perceptos[3]': \"choice([['voltearIzquierda', 'adelante'], ['voltearDerecha', 'adelante'], ['voltearIzquierda', 'voltearIzquierda', 'adelante']])\",    \n",
    "    # Si no percibe ni hedor ni brisa, avanzar una casilla.\n",
    "    'not self.perceptos[0] and not self.perceptos[1]': \"['adelante']\",\n",
    "    # Si percibe un hedor o una brisa, devolverse.\n",
    "    'self.perceptos[0] or self.perceptos[1]': \"['voltearIzquierda', 'voltearIzquierda', 'adelante']\",\n",
    "}\n",
    "\n",
    "def programaSR(self, DEB=False):\n",
    "    reaccion = self.reglas\n",
    "    for antecedente in self.reglas:\n",
    "        if eval(antecedente):\n",
    "            self.acciones += eval(reaccion[antecedente])\n",
    "            if DEB:\n",
    "                print(reaccion[antecedente])\n",
    "            break\n",
    "\n",
    "setattr(Agente, 'programa', programaSR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulamos el complortamiento del agente para evaluar su eficiencia al enfrentarse al problema del mundo del Wumpus. Trate de analizar las fortalezas y falencias del agente en el siguiente mundo. Corra la celda más de una vez, pues el agente tiene un componente aleatorio que hay que evaluar sobre varios intentos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "from IPython.display import clear_output\n",
    "\n",
    "W = Wumpus(wumpus=(3,3), oro=(1,2), pozos=[(0,3), (2,2)])\n",
    "agente = Agente()\n",
    "agente.reglas = reglas\n",
    "max_turnos = 30\n",
    "W.pintar_todo()\n",
    "plt.show()\n",
    "\n",
    "for t in range(max_turnos):\n",
    "    agente.perceptos = W.para_sentidos()\n",
    "    a = agente.reaccionar()\n",
    "    W.transicion(a)    \n",
    "    if not W.juego_activo:\n",
    "        clear_output(wait=True)\n",
    "        print(W.mensaje)\n",
    "        break\n",
    "    clear_output(wait=True)\n",
    "    W.pintar_todo()\n",
    "    plt.show()\n",
    "    sleep(.25) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora hagamos el mismo ejercicio en el siguiente mundo, en donde hemos cambiado el oro de posición. Corra la celda más de una vez, pues el agente tiene un componente aleatorio que hay que evaluar sobre varios intentos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "from IPython.display import clear_output\n",
    "\n",
    "W = Wumpus(wumpus=(3,3), oro=(3,2), pozos=[(0,3), (2,2)])\n",
    "agente = Agente()\n",
    "agente.reglas = reglas\n",
    "max_turnos = 30\n",
    "W.pintar_todo()\n",
    "plt.show()\n",
    "\n",
    "for t in range(max_turnos):\n",
    "    agente.perceptos = W.para_sentidos()\n",
    "    a = agente.reaccionar()\n",
    "    W.transicion(a)    \n",
    "    if not W.juego_activo:\n",
    "        clear_output(wait=True)\n",
    "        print(W.mensaje)\n",
    "        break\n",
    "    clear_output(wait=True)\n",
    "    W.pintar_todo()\n",
    "    plt.show()\n",
    "    sleep(.25) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 3:**\n",
    "\n",
    "Haga una tabla con una columna para las fortalezas y otra para las falencias del agente.\n",
    "\n",
    "**Respuesta:**\n",
    "\n",
    "| Fortalezas | Falencias |\n",
    "| :---: | :---: |\n",
    "| FORTALEZA 1 | FALECIA 1 |\n",
    "| FORTALEZA 2 | FALECIA 2 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Representación del mundo del Wumpus en lógica proposicional <a class=\"anchor\" id=\"representacion\"></a>\n",
    "\n",
    "([Volver al inicio](#inicio))\n",
    "\n",
    "Después de correr varias veces la simulación del agente de reflejo simple, por lo menos una cosa debe ser clara. El agente no recorre todas las casillas que podría recorrer. Es obvio que el agente necesita poder decidir, con base en la información sensorial a su disposición y su memoria sobre el pasado, cuáles casillas son seguras para transitar y así explorar una mayor parte de la caverna. En otras palabras, el agente necesita un modelo del mundo.\n",
    "\n",
    "**Agente basado en un modelo del mundo**\n",
    "\n",
    "Vamos a  representar situaciones del Mundo del Wumpus para pasar a la arquitectura de un *agente basado en un modelo*. (*model-based agent*). La siguiente imagen presenta un esquema de este tipo de agente:\n",
    "\n",
    "<img src=\"./imagenes/model-based1.png\" width=\"400\">\n",
    "\n",
    "Para lograr esto, podemos hacer que el agente sea capaz de:\n",
    "\n",
    "* Representar las reglas del mundo del Wumpus.\n",
    "* Combinar información sensorial con las reglas del mundo.\n",
    "* Razonar sobre cuáles casillas adyacentes es seguro visitar.\n",
    "* Deambular por las casillas seguras hasta encontrar el oro o agotar todas las casillas seguras y devolverse a la salida (e irse con el rabo entre las piernas). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Letras proposicionales:**\n",
    "\n",
    "Para comenzar la representación del Mundo del Wumpus, usaremos las siguientes letras proposicionales (más adelante incluiremos más):\n",
    "\n",
    "* `hedor_t` es verdadero sii el agente huele un hedor en el turno $t$.\n",
    "* `brisa_t` es verdadero sii el agente siente una brisa en el turno $t$.\n",
    "* `brillo_t` es verdadero sii el agente ve un brillo en el turno $t$.\n",
    "* `batacazo_t` es verdadero sii el agente siente un batacazo en el turno $t$.\n",
    "* `grito_t` es verdadero sii el agente escucha un grito en el turno $t$.\n",
    "* `pozo(x, y)` es verdadero sii en la casilla $(x,y)$ hay un pozo.\n",
    "* `wumpus(x, y)` es verdadero sii en la casilla $(x,y)$ está el Wumpus.\n",
    "* `segura(x, y)` es verdadero sii la casilla $(x,y)$ es segura para transitar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**De percepciones a fórmulas**\n",
    "\n",
    "Ahora usamos fórmulas de la lógica proposicional para representar aspectos del mundo. Lo primero que haremos será representar las percepciones del agente mediante una conjunción de literales. Las percepciones del agente vienen dadas mediante una lista:\n",
    "\n",
    "['hedor'/None, 'brisa'/None, 'brillo'/None, 'batacazo'/None, 'grito'/None]\n",
    "\n",
    "Usando el método `interp_percepto()` de la clase `Agente` obtenemos una fórmula con la conjunción de letras proposionales que representan los perceptos, indexados por el turno:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agentes import *\n",
    "from entornos import *\n",
    "from logica import *\n",
    "W = Wumpus()\n",
    "agente = Agente()\n",
    "agente.perceptos = W.para_sentidos()\n",
    "print(agente.interp_percepto(mundo='wumpus'))\n",
    "W.pintar_casilla()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Representando el mundo mediante reglas**\n",
    "\n",
    "Ahora consideramos la información sobre la relación entre los pozos y la brisa. Observe que las reglas del mundo dicen que en las casillas adyacentes a un pozo se siente una brisa. De manera equivalente, se sigue que si el agente no siente una briza en una casilla, entonces no hay un pozo en las casillas adyacentes. Resulta natural representar esto como una implicación:\n",
    "\n",
    "Si el agente está en $(0,0)$ y no siente una brisa, entonces no hay pozo en $(1,0)$ ni en $(0,1)$.\n",
    "\n",
    "No obstante, vamos a ceñirnos a las limitaciones de la base de conocimiento. Esto es, vamos a usar solo el lenguaje de las reglas. Así pues, en lugar de una única fórmula, debemos incluir en la base de conocimiento las dos siguientes reglas:\n",
    "\n",
    "* Si estoy en $(0,0)$ y no percibo una brisa, no hay pozo en $(1,0)$ \n",
    "* Si estoy en $(0,0)$ y no percibo una brisa, no hay pozo en $(0,1)$ \n",
    "\n",
    "Y esto para cada casilla:\n",
    "\n",
    "* Si estoy en $(1,0)$ y no percibo una brisa, no hay un pozo en $(0,0)$ \n",
    "* Si estoy en $(1,0)$ y no percibo una brisa, no hay un pozo en $(2,0)$ \n",
    "* Si estoy en $(1,0)$ y no percibo una brisa, no hay un pozo en $(1,1)$ \n",
    "* $\\vdots$\n",
    "\n",
    "La forma general de todas estas reglas es que si el agente está en la casilla $(x,y)$ y no siente una brisa, entonces no hay pozo en ninguna de sus casillas adyacentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def brisa_pozo(self):\n",
    "    \n",
    "    def truncar(x):\n",
    "        if x < 0:\n",
    "            return 0\n",
    "        elif x > 3:\n",
    "            return 3\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "    def adyacentes(casilla):\n",
    "        x, y = casilla\n",
    "        adyacentes = [\n",
    "            (truncar(x - 1), y), (truncar(x + 1), y),\n",
    "            (x, truncar(y - 1)), (x, truncar(y + 1))\n",
    "        ]\n",
    "        adyacentes = [c for c in adyacentes if c != casilla]\n",
    "        return adyacentes\n",
    "    \n",
    "    turno = agente.turno\n",
    "    casillas = adyacentes(agente.loc)\n",
    "    x, y = agente.loc\n",
    "    formulas = []\n",
    "    for c in casillas:\n",
    "        x1, y1 = c\n",
    "        formulas += [\n",
    "            f'en({x},{y})_{turno}Y-brisa_{turno}>-pozo({x1},{y1})',                \n",
    "        ]\n",
    "    return formulas\n",
    "\n",
    "setattr(Agente, 'brisa_pozo', brisa_pozo)\n",
    "\n",
    "agente = Agente()\n",
    "agente.brisa_pozo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 4:**\n",
    "\n",
    "Escriba un código que genere una lista de fórmulas `hedor_wumpus` que contenga todas las implicaciones sobre la relación entre el Wumpus y el hedor dependiendo de la casilla en que se encuentra el agente.\n",
    "\n",
    "Si el agente está en la casilla $(0,0)$, la respuesta debe ser:\n",
    "\n",
    "```\n",
    "['en(0,0)_1Y-hedor_1>-wumpus(1,0)', 'en(0,0)_1Y-hedor_1>-wumpus(0,1)']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hedor_wumpus(self):\n",
    "    \n",
    "    def truncar(x):\n",
    "        if x < 0:\n",
    "            return 0\n",
    "        elif x > 3:\n",
    "            return 3\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "    def adyacentes(casilla):\n",
    "        x, y = casilla\n",
    "        adyacentes = [\n",
    "            (truncar(x - 1), y), (truncar(x + 1), y),\n",
    "            (x, truncar(y - 1)), (x, truncar(y + 1))\n",
    "        ]\n",
    "        adyacentes = [c for c in adyacentes if c != casilla]\n",
    "        return adyacentes\n",
    "    \n",
    "    formulas = []\n",
    "    # AQUÍ COMENZA SU CÓDIGO\n",
    "    \n",
    "    # AQUÍ TERMINA SU CÓDIGO\n",
    "    \n",
    "    return formulas\n",
    "\n",
    "setattr(Agente, 'hedor_wumpus', hedor_wumpus)\n",
    "\n",
    "agente = Agente()\n",
    "agente.hedor_wumpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 5:**\n",
    "\n",
    "Escriba un código que genere una lista de fórmulas `casilla_segura`, la cual debe contener todas reglas que dicen que si en una casilla no hay ni pozo ni Wumpus, entonces es segura. (Vamos a ignorar por el momento el hecho de que la casilla sería segura incluso habiendo hedor, porque el Wumpus podría no estar vivo.)\n",
    "\n",
    "* Si no hay ni pozo ni Wumpus en $(0,0)$, entonces $(0,0)$ es segura.\n",
    "* $\\vdots$\n",
    "\n",
    "La respuesta debe ser:\n",
    "\n",
    "```\n",
    "['-pozo(0,0)Y-wumpus(0,0)>segura(0,0)',\n",
    " '-pozo(0,1)Y-wumpus(0,1)>segura(0,1)',\n",
    " '-pozo(0,2)Y-wumpus(0,2)>segura(0,2)',\n",
    " '-pozo(0,3)Y-wumpus(0,3)>segura(0,3)',\n",
    " '-pozo(1,0)Y-wumpus(1,0)>segura(1,0)',\n",
    " '-pozo(1,1)Y-wumpus(1,1)>segura(1,1)',\n",
    " '-pozo(1,2)Y-wumpus(1,2)>segura(1,2)',\n",
    " '-pozo(1,3)Y-wumpus(1,3)>segura(1,3)',\n",
    " '-pozo(2,0)Y-wumpus(2,0)>segura(2,0)',\n",
    " '-pozo(2,1)Y-wumpus(2,1)>segura(2,1)',\n",
    " '-pozo(2,2)Y-wumpus(2,2)>segura(2,2)',\n",
    " '-pozo(2,3)Y-wumpus(2,3)>segura(2,3)',\n",
    " '-pozo(3,0)Y-wumpus(3,0)>segura(3,0)',\n",
    " '-pozo(3,1)Y-wumpus(3,1)>segura(3,1)',\n",
    " '-pozo(3,2)Y-wumpus(3,2)>segura(3,2)',\n",
    " '-pozo(3,3)Y-wumpus(3,3)>segura(3,3)']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def casilla_segura(self):\n",
    "    formulas = []\n",
    "    # AQUÍ COMENZA SU CÓDIGO\n",
    "    \n",
    "    # AQUÍ TERMINA SU CÓDIGO\n",
    "    return formulas\n",
    "\n",
    "setattr(Agente, 'casilla_segura', casilla_segura)\n",
    "\n",
    "agente = Agente()\n",
    "agente.casilla_segura()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**De nuevo un mapa mental**\n",
    "\n",
    "El agente en el mundo del Wumpus también requiere un mapa mental. Definimos entonces las letras proposicionales para guardar la información de la casilla en que está el agente, mirando en qué dirección y cuáles casillas ha visitado:\n",
    "\n",
    "* en(x,y)_t es verdadero sii el agente está en la casilla $(x,y)$ en el turno $t$.\n",
    "* midando_o_t es verdadero sii el agente está mirando al oeste en el turno $t$.\n",
    "* midando_e_t es verdadero sii el agente está mirando al este en el turno $t$.\n",
    "* midando_s_t es verdadero sii el agente está mirando al sur en el turno $t$.\n",
    "* midando_n_t es verdadero sii el agente está mirando al norte en el turno $t$.\n",
    "* visitada(x,y)_t es verdadera sii el agente ha visitado la casilla $(x,y)$ en algún turno $t'\\leq t$.\n",
    "\n",
    "Y definimos todos los fluentes mencionados en el notebook anterior sobre el agente en el laberinto y que hacen relación a la creación de un mapa mental:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fluentes_mapa_mental(self):\n",
    "    turno = agente.turno\n",
    "    x, y = agente.loc\n",
    "    formulas = [\n",
    "        f'en({x},{y})_{turno}Ymirando_o_{turno}Yadelante_{turno}>en({x-1},{y})_{turno+1}',\n",
    "        f'en({x},{y})_{turno}Ymirando_e_{turno}Yadelante_{turno}>en({x+1},{y})_{turno+1}',\n",
    "        f'en({x},{y})_{turno}Ymirando_s_{turno}Yadelante_{turno}>en({x},{y-1})_{turno+1}',\n",
    "        f'en({x},{y})_{turno}Ymirando_n_{turno}Yadelante_{turno}>en({x},{y+1})_{turno+1}',\n",
    "        f'en({x},{y})_{turno}YvoltearIzquierda_{turno}>en({x},{y})_{turno+1}',\n",
    "        f'en({x},{y})_{turno}YvoltearDerecha_{turno}>en({x},{y})_{turno+1}',\n",
    "        f'en({x},{y})_{turno}Yagarrar_{turno}>en({x},{y})_{turno+1}',\n",
    "        f'mirando_o_{turno}Yadelante_{turno}>mirando_o_{turno+1}',\n",
    "        f'mirando_s_{turno}Yadelante_{turno}>mirando_s_{turno+1}',\n",
    "        f'mirando_e_{turno}Yadelante_{turno}>mirando_e_{turno+1}',\n",
    "        f'mirando_n_{turno}Yadelante_{turno}>mirando_n_{turno+1}',\n",
    "        f'mirando_o_{turno}Yagarrar_{turno}>mirando_o_{turno+1}',\n",
    "        f'mirando_s_{turno}Yagarrar_{turno}>mirando_s_{turno+1}',\n",
    "        f'mirando_e_{turno}Yagarrar_{turno}>mirando_e_{turno+1}',\n",
    "        f'mirando_n_{turno}Yagarrar_{turno}>mirando_n_{turno+1}',\n",
    "        f'mirando_o_{turno}YvoltearIzquierda_{turno}>mirando_s_{turno+1}',\n",
    "        f'mirando_s_{turno}YvoltearIzquierda_{turno}>mirando_e_{turno+1}',\n",
    "        f'mirando_e_{turno}YvoltearIzquierda_{turno}>mirando_n_{turno+1}',\n",
    "        f'mirando_n_{turno}YvoltearIzquierda_{turno}>mirando_o_{turno+1}',\n",
    "        f'mirando_o_{turno}YvoltearDerecha_{turno}>mirando_n_{turno+1}',\n",
    "        f'mirando_n_{turno}YvoltearDerecha_{turno}>mirando_e_{turno+1}',\n",
    "        f'mirando_e_{turno}YvoltearDerecha_{turno}>mirando_s_{turno+1}',\n",
    "        f'mirando_s_{turno}YvoltearDerecha_{turno}>mirando_o_{turno+1}',\n",
    "    ]\n",
    "    casillas = [(x,y) for x in range(12) for y in range(12)]\n",
    "    for c in casillas:\n",
    "        x, y = c\n",
    "        formulas += [\n",
    "            f'en({x},{y})_{turno}>visitada({x},{y})_{turno}',                \n",
    "            f'visitada({x},{y})_{turno}>visitada({x},{y})_{turno+1}',                \n",
    "        ]\n",
    "    return formulas\n",
    "\n",
    "setattr(Agente, 'fluentes_mapa_mental', fluentes_mapa_mental)\n",
    "\n",
    "agente = Agente()\n",
    "agente.fluentes_mapa_mental()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inferencias y queries\n",
    "\n",
    "Ya tenemos todo lo que necesitamos para crear una base de conocimiento inicial. Con esta base podemos implementar un programa de agente que permita transitar por todas las casillas seguras. \n",
    "\n",
    "Comenzamos por inicializar la base de conocimiento así:\n",
    "\n",
    "* Los datos serán la percepción sensorial, y la posición y dirección actual.\n",
    "* Las reglas son la dinámica del mundo que hemos codificado hasta ahora. Estas reglas incluyen:\n",
    "    - `brisa_pozo`\n",
    "    - `hedor_wumpus`\n",
    "    - `casilla_segura`\n",
    "    - `fluentes_mapa_mental`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "W = Wumpus(wumpus=(0,2), oro=(3,2), pozos=[(2,0)])\n",
    "agente = Agente()\n",
    "formulas = agente.brisa_pozo()\n",
    "formulas += agente.hedor_wumpus()\n",
    "formulas += agente.casilla_segura()\n",
    "formulas += agente.fluentes_mapa_mental()\n",
    "formulas += [f'en(0,0)_1', 'mirando_e_1']\n",
    "agente.base = LPQuery(formulas)\n",
    "agente.perceptos = W.para_sentidos()\n",
    "c = agente.interp_percepto(mundo='wumpus')\n",
    "agente.base.TELL(c)\n",
    "print(\"¡Base de conocimiento creada!\")\n",
    "print(agente.base)\n",
    "# W.pintar_casilla()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Además, observe que podemos utilizar la función `ASK` de la libreria `logica` para hacer la consulta a la base de conocimiento acerca de si una casilla es segura o no:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objetivo = 'segura(1,0)'\n",
    "print(\"Objetivo:\", objetivo)\n",
    "print()\n",
    "print(\"Datos:\", agente.base.datos)\n",
    "print()\n",
    "print(\"Reglas aplicables para el objetivo:\")\n",
    "reglas_objeto = agente.base.reglas_aplicables(objetivo)\n",
    "for r in reglas_objeto:\n",
    "    print(' Y '.join(r.cuerpo), \">\", r.cabeza)\n",
    "res = ASK(objetivo, 'success', agente.base)\n",
    "print()\n",
    "print(\"Resultado de la consulta:\", res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 6:**\n",
    "\n",
    "Cree un código que implemente el método `agente.adyacentes_seguras()` que devuelva una lista con las casillas adyacentes seguras de acuerdo a la base de conocimiento del agente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adyacentes_seguras(self):\n",
    "    \n",
    "    def truncar(x):\n",
    "        if x < 0:\n",
    "            return 0\n",
    "        elif x > 3:\n",
    "            return 3\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "    def adyacentes(casilla):\n",
    "        x, y = casilla\n",
    "        adyacentes = [\n",
    "            (truncar(x - 1), y), (truncar(x + 1), y),\n",
    "            (x, truncar(y - 1)), (x, truncar(y + 1))\n",
    "        ]\n",
    "        adyacentes = [c for c in adyacentes if c != casilla]\n",
    "        return adyacentes   \n",
    "   \n",
    "    casillas_seguras = []\n",
    "    # AQUÍ COMIENZA SU CÓDIGO\n",
    "    \n",
    "    # AQUÍ TERMINA SU CÓDIGO\n",
    "    return casillas_seguras\n",
    "\n",
    "setattr(Agente,\"adyacentes_seguras\",adyacentes_seguras)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pruebe su código con las siguientes celdas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "W = Wumpus(wumpus=(3,3), pozos=[(2,0), (2,2)])\n",
    "agente = Agente()\n",
    "formulas = agente.fluentes_mapa_mental()\n",
    "formulas += agente.brisa_pozo()\n",
    "formulas += agente.hedor_wumpus()\n",
    "formulas += agente.casilla_segura()\n",
    "formulas += [f'en(0,0)_1', 'mirando_e_1']\n",
    "agente.base = LPQuery(formulas)\n",
    "agente.perceptos = W.para_sentidos()\n",
    "c = agente.interp_percepto(mundo='wumpus')\n",
    "agente.base.TELL(c)\n",
    "agente.adyacentes_seguras()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La respuesta debe ser:\n",
    "\n",
    "```\n",
    "[(1, 0), (0, 1)]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "W = Wumpus(wumpus=(1,0), oro=(3,2), pozos=[(2,0), (2,2)])\n",
    "agente = Agente()\n",
    "formulas = agente.fluentes_mapa_mental()\n",
    "formulas += agente.brisa_pozo()\n",
    "formulas += agente.hedor_wumpus()\n",
    "formulas += agente.casilla_segura()\n",
    "formulas += [f'en(0,0)_1', 'mirando_e_1']\n",
    "agente.base = LPQuery(formulas)\n",
    "agente.perceptos = W.para_sentidos()\n",
    "c = agente.interp_percepto(mundo='wumpus')\n",
    "agente.base.TELL(c)\n",
    "agente.adyacentes_seguras()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La respuesta debe ser:\n",
    "\n",
    "```\n",
    "[]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Estimación de estados**\n",
    "\n",
    "La base de conocimiento crece cada turno, puesto que vamos incluyendo cada vez más y más reglas y datos en ella. Esto genera, evidentemente, que las consultas sean cada vez más demoradas. Para solucionar este inconveniente, debemos mantener un tamaño relativamente constante de la base de conocimiento. Esto lo logramos mediante una estimación de estado, que consiste en solo guardar la información relevante en memoria del estado actual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimar_estado(self, W):\n",
    "    self.base.TELL(f'segura({self.loc[0]},{self.loc[1]})')\n",
    "    cas_seguras = self.adyacentes_seguras()\n",
    "    self.base.TELL('Y'.join([f'segura({c[0]},{c[1]})' for c in cas_seguras]))\n",
    "    nueva_dir = self.nueva_direccion()\n",
    "    self.base.TELL(nueva_dir)\n",
    "    nueva_pos = self.nueva_posicion()\n",
    "    self.base.TELL(nueva_pos)\n",
    "    formulas = [d for d in self.base.datos if f'_{self.turno}' in d]\n",
    "    formulas += [s for s in self.base.datos if 'segura' in s]\n",
    "    formulas += agente.fluentes_mapa_mental()\n",
    "    formulas += agente.brisa_pozo()\n",
    "    formulas += agente.hedor_wumpus()\n",
    "    formulas += agente.casilla_segura()\n",
    "    formulas += self.casillas_visitadas()\n",
    "    agente.perceptos = W.para_sentidos()\n",
    "    formulas += [agente.interp_percepto(mundo='wumpus')]\n",
    "    self.base = LPQuery(formulas)\n",
    "  \n",
    "setattr(Agente,'estimar_estado',estimar_estado)\n",
    "\n",
    "def casillas_visitadas(self):\n",
    "    turno = self.turno\n",
    "    # Guardamos las casillas visitadas\n",
    "    visitadas = []\n",
    "    casillas = [(x,y) for x in range(4) for y in range(4)]\n",
    "    for c in casillas:\n",
    "        x, y = c\n",
    "        consulta = ASK(f'visitada({x},{y})_{turno}', 'success', self.base)\n",
    "        if consulta:\n",
    "            visitadas.append(f'visitada({x},{y})_{turno}')\n",
    "    return visitadas\n",
    "\n",
    "setattr(Agente,'casillas_visitadas',casillas_visitadas)\n",
    "\n",
    "def nueva_posicion(self):\n",
    "    \n",
    "    def truncar(x):\n",
    "        if x < 0:\n",
    "            return 0\n",
    "        elif x > 3:\n",
    "            return 3\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "    def adyacentes(casilla):\n",
    "        x, y = casilla\n",
    "        adyacentes = [\n",
    "            (truncar(x - 1), y), (truncar(x + 1), y),\n",
    "            (x, truncar(y - 1)), (x, truncar(y + 1))\n",
    "        ]\n",
    "        adyacentes = [c for c in adyacentes if c != casilla]\n",
    "        return adyacentes \n",
    "    \n",
    "    casillas = [self.loc] + adyacentes(self.loc)\n",
    "    for c in casillas:\n",
    "        x, y = c\n",
    "        pos = f'en({x},{y})_{self.turno}'\n",
    "        evaluacion = ASK(pos, 'success', self.base)\n",
    "        if evaluacion:\n",
    "            self.loc = (x,y)\n",
    "            return pos\n",
    "    raise Exception('¡No se encontró posición!')\n",
    "\n",
    "setattr(Agente,'nueva_posicion',nueva_posicion)\n",
    "\n",
    "def nueva_direccion(self):\n",
    "    direcciones = ['o', 'e', 's', 'n']\n",
    "    for d in direcciones:\n",
    "        direccion = f'mirando_{d}_{self.turno}'\n",
    "        evaluacion = ASK(direccion, 'success', self.base)\n",
    "        if evaluacion:\n",
    "            return direccion\n",
    "    raise Exception('¡No se encontró dirección!')\n",
    "            \n",
    "setattr(Agente,'nueva_direccion',nueva_direccion)\n",
    "\n",
    "def solo_direccion(self):\n",
    "    direcciones = ['o', 'e', 's', 'n']\n",
    "    dir_direcciones = {'o':'oeste', 'e':'este', 's':'sur', 'n':'norte'}\n",
    "    for d in direcciones:\n",
    "        direccion = f'mirando_{d}_{self.turno}'\n",
    "        if direccion in self.base.datos:\n",
    "            return dir_direcciones[d]\n",
    "    raise Exception('¡No se encontró dirección!')\n",
    "            \n",
    "setattr(Agente,'solo_direccion',solo_direccion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Programa basado en un modelo del mundo**\n",
    "\n",
    "Para completar una versión mínima de nuestro heroe, capaz de entrar en la caverna del Wumpus sin morir en el intento, debemos implementar el programa de agente. Las reglas que sigue el agente son las siguientes:\n",
    "\n",
    "* Si percibe el brillo (indicando que en esa casilla está el oro), lo agarra.\n",
    "* Si no percibe brillo, considera las casillas adyacentes seguras que no haya visitado y se dirige a una de ellas.\n",
    "* Si todas las casillas adyacentes seguras ya han sido visitadas, selecciona una casilla adyacente segura para ir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cache(self):\n",
    "    turno = self.turno\n",
    "    casilla_actual = self.loc\n",
    "    direccion = self.solo_direccion()\n",
    "    cas_seguras = self.adyacentes_seguras()\n",
    "    cas_seguras = [c for c in cas_seguras if c != casilla_actual]\n",
    "    cas_visitadas = self.casillas_visitadas()\n",
    "    cas_visitadas = [tuple([int(s[9]),int(s[11])]) for s in cas_visitadas]\n",
    "    return turno, casilla_actual, direccion, cas_seguras, cas_visitadas\n",
    "\n",
    "setattr(Agente, 'cache', cache)\n",
    "\n",
    "def programaKB(self, DEB=False):\n",
    "    acciones = []\n",
    "    turno, casilla_actual, direccion, cas_seguras, cas_visitadas = self.cache()\n",
    "    if DEB:\n",
    "        print('Turno acutal:', turno)\n",
    "        print('Casilla actual:', casilla_actual)\n",
    "        print('Dirección actual:', direccion)\n",
    "        print('Casillas adyacentes seguras:', cas_seguras)\n",
    "        print('Casillas visitadas:', cas_visitadas)\n",
    "    if ASK(f'brillo_{turno}','success',self.base):\n",
    "        if DEB:\n",
    "            print('¡Oh, el oro!')\n",
    "        acciones.append('agarrar')\n",
    "    else:\n",
    "        opciones = [casilla for casilla in cas_seguras if casilla not in cas_visitadas]\n",
    "        if DEB:\n",
    "            print('Casillas opcionales:', opciones)\n",
    "        if len(opciones) > 0:\n",
    "            casilla_ir = choice(opciones)\n",
    "            if DEB:\n",
    "                print('El agente quiere ir a la casilla', casilla_ir)\n",
    "            camino = [casilla_actual, casilla_ir]\n",
    "            acciones = acciones_camino(camino, direccion)\n",
    "        elif len(cas_seguras) > 0:\n",
    "            casilla_ir = choice(cas_seguras)\n",
    "            if DEB:\n",
    "                print('El agente quiere devolverse a la casilla', casilla_ir)\n",
    "            camino = [casilla_actual, casilla_ir]\n",
    "            acciones = acciones_camino(camino, direccion)\n",
    "        else:\n",
    "            print(\"¡Caso no contemplado!\")\n",
    "    self.acciones += acciones\n",
    "\n",
    "setattr(Agente, 'programa', programaKB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explorando de manera segura**\n",
    "\n",
    "El agente ya puede explorar el entorno de manera segura. Veamos unos cuantos turnos con toda la información que el agente va encontrando y deduciendo durante su exploración:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "from agentes import *\n",
    "\n",
    "W = Wumpus(wumpus=(3,3), oro=(1,2), pozos=[(0,3), (2,2)])\n",
    "agente = Agente()\n",
    "formulas = agente.fluentes_mapa_mental()\n",
    "formulas += agente.brisa_pozo()\n",
    "formulas += agente.hedor_wumpus()\n",
    "formulas += agente.casilla_segura()\n",
    "formulas += [f'en(0,0)_1', 'mirando_e_1', 'segura(0,0)']\n",
    "agente.base = LPQuery(formulas)\n",
    "agente.perceptos = W.para_sentidos()\n",
    "c = agente.interp_percepto(mundo='wumpus')\n",
    "agente.base.TELL(c)\n",
    "W.pintar_todo()\n",
    "plt.show()\n",
    "sleep(.5) \n",
    "\n",
    "for i in range(5):\n",
    "    a = agente.reaccionar(DEB=True)\n",
    "    formula_accion = f'{a}_{agente.turno-1}'\n",
    "    agente.base.TELL(formula_accion)\n",
    "    W.transicion(a)\n",
    "    agente.estimar_estado(W)\n",
    "    W.pintar_todo()\n",
    "    plt.show()\n",
    "    sleep(.5) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora visualizamos en forma de video la exploración por algunos turnos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "from agentes import *\n",
    "\n",
    "W = Wumpus(wumpus=(3,3), oro=(1,2), pozos=[(0,3), (2,2)])\n",
    "agente = Agente()\n",
    "formulas = agente.fluentes_mapa_mental()\n",
    "formulas += agente.brisa_pozo()\n",
    "formulas += agente.hedor_wumpus()\n",
    "formulas += agente.casilla_segura()\n",
    "formulas += [f'en(0,0)_1', 'mirando_e_1', 'segura(0,0)']\n",
    "agente.base = LPQuery(formulas)\n",
    "agente.perceptos = W.para_sentidos()\n",
    "c = agente.interp_percepto(mundo='wumpus')\n",
    "agente.base.TELL(c)\n",
    "W.pintar_todo()\n",
    "plt.show()\n",
    "sleep(.5) \n",
    "\n",
    "for i in range(30):\n",
    "    a = agente.reaccionar()\n",
    "    formula_accion = f'{a}_{agente.turno-1}'\n",
    "    agente.base.TELL(formula_accion)\n",
    "    W.transicion(a)\n",
    "    if not W.juego_activo:\n",
    "        clear_output(wait=True)\n",
    "        W.pintar_todo()\n",
    "        print(W.mensaje)\n",
    "        break\n",
    "    agente.estimar_estado(W)\n",
    "    clear_output(wait=True)\n",
    "    W.pintar_todo()\n",
    "    plt.show()\n",
    "    sleep(.5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agente basado en objetivos <a class=\"anchor\" id=\"goalba\"></a>\n",
    "\n",
    "([Volver al inicio](#inicio))\n",
    "\n",
    "En este punto ya hemos creado muchos de los aspectos más importantes del agente basado en conocimiento. No obstante, aún se requiere un aspecto muy importante de planeación de rutas. Poder diseñar estos planes es esencial para que el agente pueda devolverse a la casilla inicial y salir de la cueva. \n",
    "\n",
    "Al incluir la planeación de objetivos en la arquitectura del agente, estamos un paso más arriba en la jerarquía propuesta por Russell & Norvig. En efecto, estamos considerando una arquitectura de *agente basado en objetivos* (*goal-based agent*). La siguiente imagen presenta un esquema de este tipo de arquitectura:\n",
    "\n",
    "<img src=\"./imagenes/goal-based.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Planeación de rutas**\n",
    "\n",
    "Planear una ruta desde la casilla actual hasta una casilla objetivo a la cual se desea ir es un problema muy similar a los que ya hemos encontrado en sesiones pasadas. Debemos definir un ambiente de tarea `Rejilla` y luego usar un algoritmo de búsqueda sobre este.\n",
    "\n",
    "El ambiente se inicializa con una casilla `actual`, una `objetivo` y una lista de casillas `seguras`. Los aspectos más importantes de la definición formal del ambiente de tarea son los siguientes:\n",
    "\n",
    "* **acciones_aplicables**(`casilla`): Las casillas adyacentes a `casilla` que estén incluidas en la lista `seguras`.\n",
    "* **costo**: distancia Manhattan entre las casillas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 7:**\n",
    "\n",
    "Complete la siguiente clase para implementar el ambiente de tarea `Rejilla`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rejilla:\n",
    "    '''\n",
    "    Problema del tránsito por la rejilla\n",
    "    desde donde está el héroe hasta una\n",
    "    casilla objetivo\n",
    "    Parámetros:\n",
    "        - inicial, una casilla de la forma (x,y)\n",
    "        - objetivo, una casilla de la forma (x,y)\n",
    "        - seguras, una lista de casillas que restringen\n",
    "                    las acciones aplicables\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, inicial, objetivo, seguras):\n",
    "        self.estado_inicial = inicial\n",
    "        self.estado_objetivo = objetivo\n",
    "        self.casillas_seguras = seguras\n",
    "    \n",
    "    def adyacentes(self, casilla):\n",
    "        def truncar(x):\n",
    "            if x < 0:\n",
    "                return 0\n",
    "            elif x > 3:\n",
    "                return 3\n",
    "            else:\n",
    "                return x\n",
    "        x, y = casilla\n",
    "        adyacentes = [\n",
    "            (truncar(x - 1), y), (truncar(x + 1), y),\n",
    "            (x, truncar(y - 1)), (x, truncar(y + 1))\n",
    "        ]\n",
    "        adyacentes = [c for c in adyacentes if c != casilla]\n",
    "        return adyacentes\n",
    "    \n",
    "    def acciones_aplicables(self, estado):\n",
    "        pass\n",
    "        # AQUÍ SU COMIENZA SU CÓDIGO\n",
    "        # AQUÍ TERMINA SU CÓDIGO\n",
    "\n",
    "    def transicion(self, estado, accion):\n",
    "        pass\n",
    "        # AQUÍ SU COMIENZA SU CÓDIGO\n",
    "        # AQUÍ TERMINA SU CÓDIGO\n",
    "       \n",
    "    def test_objetivo(self, estado):\n",
    "        pass\n",
    "        # AQUÍ SU COMIENZA SU CÓDIGO\n",
    "        # AQUÍ TERMINA SU CÓDIGO\n",
    "    \n",
    "    def costo(self, estado, accion):\n",
    "        pass\n",
    "        # AQUÍ SU COMIENZA SU CÓDIGO\n",
    "        # AQUÍ TERMINA SU CÓDIGO\n",
    "    \n",
    "    def codigo(self, estado):\n",
    "        x, y = estado\n",
    "        return f\"{x}-{y}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Compruebe su código con la siguiente celda:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from busqueda import best_first_search, solucion\n",
    "\n",
    "seguras = [(x, y) for x in range(4) for y in range(4)]\n",
    "R = Rejilla((3,2), (0,0), seguras)\n",
    "camino = best_first_search(R)\n",
    "camino = solucion(camino)\n",
    "print(camino)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La respuesta debe ser:\n",
    "\n",
    "```\n",
    "[(2, 2), (1, 2), (1, 1), (0, 1), (0, 0)]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 8:**\n",
    "\n",
    "Ahora necesitamos encontrar todas las casillas seguras que conozcamos hasta el momento. Implemente el método `todas_segura` para la clase `Agente`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def todas_seguras(self):\n",
    "    pass\n",
    "    # AQUÍ SU COMIENZA SU CÓDIGO\n",
    "    # AQUÍ TERMINA SU CÓDIGO\n",
    "\n",
    "setattr(Agente,\"todas_seguras\",todas_seguras)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Pruébe el código con la siguiente celda:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "W = Wumpus(wumpus=(0,2), oro=(2,3), pozos=[(2,0), (3,2)])\n",
    "agente = Agente()\n",
    "formulas = agente.fluentes_mapa_mental()\n",
    "formulas += agente.brisa_pozo()\n",
    "formulas += agente.hedor_wumpus()\n",
    "formulas += agente.casilla_segura()\n",
    "formulas += [f'en(0,0)_1', 'mirando_e_1', 'segura(0,0)']\n",
    "agente.base = LPQuery(formulas)\n",
    "agente.perceptos = W.para_sentidos()\n",
    "c = agente.interp_percepto(mundo='wumpus')\n",
    "agente.base.TELL(c)\n",
    "\n",
    "agente.turno += 1\n",
    "a = 'voltearIzquierda'\n",
    "W.transicion(a)\n",
    "formula_accion = f'{a}_{agente.turno-1}'\n",
    "agente.base.TELL(formula_accion)\n",
    "agente.estimar_estado(W)\n",
    "\n",
    "agente.turno += 1\n",
    "a = 'adelante'\n",
    "W.transicion(a)\n",
    "formula_accion = f'{a}_{agente.turno-1}'\n",
    "agente.base.TELL(formula_accion)\n",
    "agente.estimar_estado(W)\n",
    "\n",
    "agente.turno += 1\n",
    "a = 'voltearDerecha'\n",
    "W.transicion(a)\n",
    "formula_accion = f'{a}_{agente.turno-1}'\n",
    "agente.base.TELL(formula_accion)\n",
    "agente.estimar_estado(W)\n",
    "\n",
    "agente.turno += 1\n",
    "a = 'adelante'\n",
    "W.transicion(a)\n",
    "formula_accion = f'{a}_{agente.turno-1}'\n",
    "agente.base.TELL(formula_accion)\n",
    "agente.estimar_estado(W)\n",
    "\n",
    "agente.turno += 1\n",
    "a = 'voltearIzquierda'\n",
    "W.transicion(a)\n",
    "formula_accion = f'{a}_{agente.turno-1}'\n",
    "agente.base.TELL(formula_accion)\n",
    "agente.estimar_estado(W)\n",
    "\n",
    "agente.turno += 1\n",
    "a = 'adelante'\n",
    "W.transicion(a)\n",
    "formula_accion = f'{a}_{agente.turno-1}'\n",
    "agente.base.TELL(formula_accion)\n",
    "agente.estimar_estado(W)\n",
    "\n",
    "W.pintar_todo()\n",
    "\n",
    "print(agente.todas_seguras())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La respuesta debe ser:\n",
    "\n",
    "```\n",
    "[(0, 0), (0, 1), (1, 0), (1, 1), (1, 2), (2, 1)]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora modificamos el programa de agente para incluir el objetivo de que, si ya encontramos el oro, nos vamos derecho a la salida trazando una ruta por las casillas seguras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def programaKB(self, DEB=False):\n",
    "    acciones = []\n",
    "    turno, casilla_actual, direccion, cas_seguras, cas_visitadas = self.cache()\n",
    "    if DEB:\n",
    "        print('Turno acutal:', turno)\n",
    "        print('Casilla actual:', casilla_actual)\n",
    "        print('Dirección actual:', direccion)\n",
    "        print('Casillas adyacentes seguras:', cas_seguras)\n",
    "        print('Casillas visitadas:', cas_visitadas)\n",
    "    if ASK(f'brillo_{turno}','success',self.base):\n",
    "        if DEB:\n",
    "            print('¡Oh, el oro!')\n",
    "        acciones.append('agarrar')\n",
    "        R = Rejilla(casilla_actual, (0,0), self.todas_seguras())\n",
    "        camino = best_first_search(R)\n",
    "        camino = [casilla_actual] + solucion(camino)\n",
    "        acciones += acciones_camino(camino, direccion)\n",
    "        acciones.append('salir')\n",
    "    else:\n",
    "        opciones = [casilla for casilla in cas_seguras if casilla not in cas_visitadas]\n",
    "        if DEB:\n",
    "            print('Casillas opcionales:', opciones)\n",
    "        if len(opciones) > 0:\n",
    "            casilla_ir = choice(opciones)\n",
    "            if DEB:\n",
    "                print('El agente quiere ir a la casilla', casilla_ir)\n",
    "            camino = [casilla_actual, casilla_ir]\n",
    "            acciones = acciones_camino(camino, direccion)\n",
    "        elif len(cas_seguras) > 0:\n",
    "            casilla_ir = choice(cas_seguras)\n",
    "            if DEB:\n",
    "                print('El agente quiere devolverse a la casilla', casilla_ir)\n",
    "            camino = [casilla_actual, casilla_ir]\n",
    "            acciones = acciones_camino(camino, direccion)\n",
    "        else:\n",
    "            print(\"¡Caso no contemplado!\")\n",
    "    self.acciones += acciones\n",
    "\n",
    "setattr(Agente, 'programa', programaKB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "from agentes import *\n",
    "\n",
    "W = Wumpus(wumpus=(3,3), oro=(1,2), pozos=[(0,3), (2,2)])\n",
    "agente = Agente()\n",
    "formulas = agente.fluentes_mapa_mental()\n",
    "formulas += agente.brisa_pozo()\n",
    "formulas += agente.hedor_wumpus()\n",
    "formulas += agente.casilla_segura()\n",
    "formulas += [f'en(0,0)_1', 'mirando_e_1', 'segura(0,0)']\n",
    "agente.base = LPQuery(formulas)\n",
    "agente.perceptos = W.para_sentidos()\n",
    "c = agente.interp_percepto(mundo='wumpus')\n",
    "agente.base.TELL(c)\n",
    "W.pintar_todo()\n",
    "plt.show()\n",
    "sleep(.5) \n",
    "\n",
    "for i in range(30):\n",
    "    a = agente.reaccionar()\n",
    "    formula_accion = f'{a}_{agente.turno-1}'\n",
    "    agente.base.TELL(formula_accion)\n",
    "    W.transicion(a)\n",
    "    if not W.juego_activo:\n",
    "        clear_output(wait=True)\n",
    "        W.pintar_todo()\n",
    "        print(W.mensaje)\n",
    "        break\n",
    "    agente.estimar_estado(W)\n",
    "    clear_output(wait=True)\n",
    "    W.pintar_todo()\n",
    "    plt.show()\n",
    "    sleep(.5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### En este notebook usted aprendió\n",
    "\n",
    "* El mundo del Wumpus.\n",
    "* Uso de la lógica proposicional para representar las reglas del mundo del Wumpus.\n",
    "* Resolver el problema de trazar una ruta desde la casilla actual hasta la casilla de salida transitando sólo por casillas seguras.\n",
    "* Incluir en el programa de agente el objetivo de que, una vez tomado el oro, debemos dirigirnos de manera segura a la casilla de salida."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "arboles_busqueda.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
