{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clase 12: Redes Neuronales\n",
    "\n",
    "En esta clase vamos a construir el concepto de una red neuronal artificial a partir de las unidades básicas *las neuronas artificiales* especificamente desde las **neuronas logisticas**, e introduciremos el algoritmo de backpropagation.\n",
    "\n",
    "## La neurona logistica\n",
    "\n",
    "Suponga se tiene un perceptrón cuya función de activacón $\\displaystyle \\varphi(\\mathbf{x}) = \\frac{1}{a+e^{-\\boldsymbol\\omega^T\\mathbf{x}}}$. Como se muestra en la figura\n",
    "\n",
    "<img src=\"img/Logistic_Neuron.png\" width=\"600\">\n",
    "\n",
    "**Pregunta:** ¿a qué se parece esto?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solución:** Es una regresión logistica normal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redes Neuronales\n",
    "\n",
    "Supongamos que tal como sucede con las neuronas biologicas, queremos agrupar las neuronas artificiales. Para hacer esto definimos un aarquitectura por capas, donde una capa es un conjunto de neuronas que estan conectadas a todos los elementos de las capas anteriores. De esta forma se obtiene una estructura como la de la figura:\n",
    "\n",
    "<img src=\"img/RNA.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta estructura, cada uno de los nodos representa una neurona logística. Los demás elementos de interés son:\n",
    "\n",
    "1. Capa de Entrada: La capa de conexión de los elementos de entrada a la red. Esta capa no tiene una función de activación, solo representa la interfaz de conexión con los datos de entrada.\n",
    "2. Capa de Salida: Elementos que proporcionan la salida de la red\n",
    "3. Capas ocultas: Capas que se encuentran entre la capa de entrada y la capa de salida.\n",
    "4. Pesos (Parámetros): Cada línea que conecta un nodo con el siguiente se considera que es el valor anterior multiplicado por un peso.\n",
    "\n",
    "### Nomenclatura\n",
    "\n",
    "Para poder entender un poco mejor los procesos que vamos a seguir a continuación definamos la siguiente nomenclatura:\n",
    "\n",
    "* $a_i^{(j)}$ es la salida de la función de activación de la neurona $i$ en la capa $j$, con $j=1$ la capa de entrada.\n",
    "* $\\omega_{ik}^{(j)}$ es el peso de la capa $j$ que conecta a la neurona $k$ de la capa $j$ con la neurona $i$ de la capa $j+1$. \n",
    "* $\\mathbf{W}^{(j)}$ es la matrix de pesos relacionada con la capa $j$.\n",
    "\n",
    "Supongamos se tiene la siguiente red neuronal:\n",
    "\n",
    "<img src=\"img/RNA_Elements.png\" width=\"600\">\n",
    "\n",
    "**Pregunta:** ¿Cómo definimos la matrix de pesos $\\mathbf{W}^{(1)}$ y $\\mathbf{W}^{(2)}$, las salidas de las fucniones de activación y demás?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solución:** Las matrices quedan definidas de la siguiente forma:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "    \\mathbf{W}^{(1)}=\n",
    "    \\begin{bmatrix}\n",
    "        \\omega^{(1)}_{11} & \\omega^{(1)}_{12} & \\omega^{(1)}_{13}\\\\\n",
    "        \\omega^{(1)}_{21} & \\omega^{(1)}_{22} & \\omega^{(1)}_{23}\\\\\n",
    "        \\omega^{(1)}_{31} & \\omega^{(1)}_{32} & \\omega^{(1)}_{33}\n",
    "    \\end{bmatrix};\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "y \n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "    \\left(\\mathbf{W}^{(2)}\\right)^{\\text{T}}=\n",
    "    \\begin{bmatrix}\n",
    "        \\omega^{(2)}_{11} \\\\\n",
    "        \\omega^{(2)}_{12} \\\\\n",
    "        \\omega^{(2)}_{13}\n",
    "    \\end{bmatrix}.\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "\n",
    "de allí podemos calcular las salidas de las funciones de activación como $a_i^{(j)} = g(z_i^{(j)})$, donde $\\displaystyle g(x) = \\frac{1}{1+e^{(-x)}}$, y $z_i^{(j)} = \\mathbf{W}^{(j-1)}_{i:}\\mathbf{a}^{(j-1)}$, con $\\mathbf{W}^{(j-1)}_{i:}$ la $i$-ésima fila de la matriz $\\mathbf{W}^{(j-1)}$ y $\\mathbf{a}^{(j-1)}= [a_1^{(j-1)} \\quad a_2^{(j-1)} \\quad a_2^{(j-1)} ]$. Tenga en cuenta que  $\\mathbf{a}^{(1)} = \\mathbf{x}^{(1)}$.\n",
    "\n",
    "Finalmente, para esta red, la salida se calcula como:\n",
    "\n",
    "$$h_{\\mathbf{W}}(\\mathbf{x}) = g\\left(\\mathbf{W}^{(2)}\\mathbf{a}^{(2)}\\right).$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento de una red neuronal\n",
    "\n",
    "Para entrenar una red neuronal el objetivo es encontrar el valor de los pesos (parámetros) $\\omega$ que minimizan una función de costo. Sin embargo existen varios problemas cuando se usan neuronas tipo adaline y el perceptron.\n",
    "\n",
    "**Pregunta:** ¿Qué problemas tiene el usar neuronas tipo perceptron o adaline?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solución:** Existen varios problemas al usar este tipo de neuronas, entre los problemas encontramos:\n",
    "1. La función de activación es discontinua, por lo cual su derivada no existe y no es posible usar gradiente descendiente.\n",
    "2. El valor del umbral utilizado en las neuronas tradicionales es problematico.\n",
    "\n",
    "Para dar solución al primer problema se utilizan en lugar de una función de umbral la función logistica, es decir se utilizan neuronas logisticas. Para solucionar el segundo problema se modifica la estrucutra de las neuronas, se les agrega una entrada de valor uno, con un peso $\\omega^{(j)}_0$, de esta forma la comparación se hace después comparando con cero. Esto viene del siguiente analysis:\n",
    "\n",
    "suponga se tiene un perceptron cuya salida esta dada pro una función de umbral con threshold $T$, la salida es uno si el producto $\\boldsymbol\\omega^{\\text{T}}\\mathbf{x}\\geq T$. Por lo tanto, la salida sera uno si  $\\boldsymbol\\omega^{\\text{T}}\\mathbf{x}-T\\geq0$, esta ecuación se puede representar por medio de $[-T \\quad \\boldsymbol\\omega]^{\\text{T}}[1 \\quad \\mathbf{x}]\\geq0$, si asumimos que $\\omega_0 = -T$, obtenemos una expresión similar par a la evaluación del perceptón, sin tener probelmas con los umbrales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si observamos la estructura de la red neuronal, podemos decir que la salida de una capa es una función logistica, que luego alimenta a la capa que sigue, la cual pasa a su vez por una función logística y así sucesivamente. Es decir, para unos datos de entrada $\\mathbf{x}$, la red calcula una función del tipo $g(\\mathbf{x})=f^{(n)}\\left({\\mathbf{W}^{(n)}}f^{(n-1)}\\left({\\mathbf{W}^{(n-1)}}f^{(n-2)}\\left({\\mathbf{W}^{(n-2)}}\\ldots\\left(f^{(1)}({\\mathbf{W}^{(1)}}\\mathbf{x})\\right)\\right)\\right)\\right)$, es decir se tiene una función compuesta a la salida. Cada una de esas funciónes depende no solo de los valores de la entrada sino de los pesos de la red neuronal. \n",
    "\n",
    "**Pregunta:** ¿Qué puedo utilizar para encontrar el valor de los pesos?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solución:** Se puede utilizar gradiente descendiente, se define una función de costo y se minimiza utilizando gradiente descendiente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pregunta:** Gradiente descendiente actualiza los pesos basado en la derivada de la función de costo, y par aesto requiere el calculo del error, pero el error solo se puede calcular en la última capa ¿Cómo puedo usar gradiente descendiente para actualizar los pesos en el algoritmo de gradiente descendiente?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solución:** Se utiliza la propagación hacia atras del error, **back propagation**. Las redes con perceptrones multicapa fueron concebidas desde los 60, justo despues de haber sido propuesto el perceptrón. Sin embargo la idea de eliminar el threshold del problema colocandolo en los pesos a encontrar, de utilizar función logistica en lugar de la función de umbral, y de utilizar herramientas de diferenciación automatica (fundamento de back-propagation) demoró alrededor de 25 años en ser utilizada en las redes neuronales. Pro esta razón las redes perdieron popularidad entre los años 60-80. Cuando se propuso el uso de back-propagation para redes neuronales alrededor de 1982, estas se volvieron a popularizar. Hoy en día las redes neuronales profundas (basadas en los principios que estamos viendo en clase, pero que tienen muchas mas capas y una cantidad mucho mayor de pesos) son el estado del arte en Machine Learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Back-Propagation\n",
    "\n",
    "Backpropagation toma ventaja del hecho de que el cambio en la función de costo con respecto a un peso se puede obtener capa a capa, esto se debe a que la unica forma que los pesos de la capa $j$, $\\mathbf{W}^{(j)}$ afecten a la función de costo es pasando a travez de las diferentes capas hasta llegar a la salida. Y la forma como afecta al costo dsegún la siguiente capa es lineal. De esta forma no tenemos qu eencontrar todas las derivadas del costo respecto a cada uno de los pesos, sino qu epodemos usar la información redundante en estas expresiones para hacer un algoritmo más eficiente. En si esta eficiencia se puede resumir en dos propiedades:\n",
    "\n",
    "1. Para caluclar el gradiente en la capa $j$ us la información de las capas posteriores hasta la capa de salida, estos no se deben recalcular.\n",
    "2. Evita el clculo innecesario de las derivadas de las ssalidas intermedias con respecto a los pesos. Ya qu elo que hace es garantizar que efectivamentes siempre se esta calcualndo la derivada en función de la ultima capa.\n",
    "\n",
    "Backpropagation se puede observar como la multiplicación de matrices, ajustando esta multiplicación se puede obtener una forma más eficiente de actualizar los pesos de la red.\n",
    "\n",
    "De forma general, se tiene la función de cosoto $J(y_i,g(\\mathbf{x}_i))$, de forma vectorial esta se puede escribir como:\n",
    "\n",
    "$$J\\left(\\mathbf{y},f^{(n)}\\left({\\mathbf{W}^{(n)}}f^{(n-1)}\\left({\\mathbf{W}^{(n-1)}}f^{(n-2)}\\left({\\mathbf{W}^{(n-2)}}\\ldots\\left(f^{(1)}({\\mathbf{W}^{(1)}}\\mathbf{x})\\right)\\right)\\right)\\right)\\right)$$\n",
    "\n",
    "sea la entrada a la capa $j$ expresada por $\\mathbf{z}^{(j)}$ y la salida de la función de activación $\\mathbf{a}^{(j)}$, de tal forma que $\\mathbf{z}^{(j)}=\\mathbf{W}^{(j-1)}\\mathbf{a}^{(j-1)}$.\n",
    "\n",
    "El procedieminto apra derivar la regla de actualización de los pesos usando gradiente descendeinte es el siguiente:\n",
    "\n",
    "1. Evalue en feedforward la salida de la red para unos valores dados de $\\mathbf{W}$\n",
    "2. Calcule la derivada del costo en función de las entradas $\\mathbf{x}$.\n",
    "3. Reacomode el calculo de talforma que a la derecha queden los términos de las últimas capas y a la izquierda lo de las primeras capas.\n",
    "4. Para la capa $j$, calcule la derivada del costo en función de los pesos $\\mathbf{W}^{(j)}$.\n",
    "5. Use este resultado para actualizar los pesos de la capa $j$.\n",
    "6. Propague hace atras el calculo de las derivadas de forma recursiva.\n",
    "\n",
    "tratemos de entender esto un poco.\n",
    "\n",
    "1. Evaluación feed forward de la red: Calcular segun un conjunto de entradas y un conjunto de pesos definido $\\mathbf{W}$ las salidas $\\mathbf{z}^{(j)}$ y $\\mathbf{z}^{(j)}$ para toda la red.\n",
    "\n",
    "2. Para caluclar estas derivadas usemos como referencia la siguiente imagen:\n",
    "\n",
    "<img src=\"img/Red_structure.png\" width=\"600\">\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "como el costo depende de la salida, se puede evaluar como si estuvieramos calculando el costo en la salida. Par aesto calculemos la derivada del costo en función de la entrada $\\mathbf{(x)}$. Esto nos da:\n",
    "\n",
    "$$\\frac{\\partial\\mathbf{J}}{\\partial\\mathbf{x}} = \\frac{\\partial\\mathbf{J}}{\\partial\\mathbf{a}^{(L)}}.\\frac{\\partial\\mathbf{a}^{(L)}}{\\partial\\mathbf{z}^{(L)}}.\\frac{\\partial\\mathbf{z}^{(L)}}{\\partial\\mathbf{a}^{(L-1)}}.\\frac{\\partial\\mathbf{a}^{(L-1)}}{\\partial\\mathbf{z}^{(L-1)}}.\\frac{\\partial\\mathbf{z}^{(L-1)}}{\\partial\\mathbf{a}^{(L-2)}}\\ldots\\frac{\\partial\\mathbf{a}^{(2)}}{\\partial\\mathbf{z}^{(2)}}.\\frac{\\partial\\mathbf{z}^{(2)}}{\\partial\\mathbf{x}}$$\n",
    "\n",
    "De aqui podemos observar que las derivadas parciales de las salidas de la función de activación con respecto a las entradas, no es más que las derivadas de las funciones de activación, entonces podemos reemplazar todos los terminos $\\displaystyle\\frac{\\partial\\mathbf{a}^{(L)}}{\\partial\\mathbf{z}^{(L)}}=\\left(f^{(L)}\\right)'$. Por otro lado como $\\mathbf{z}^{(L)} = \\mathbf{W}^{(L-1)}\\mathbf{a^{(L-1)}}$, entonces los terminos $\\displaystyle\\frac{\\partial\\mathbf{z}^{(L)}}{\\partial\\mathbf{a}^{(L-1)}}=\\mathbf{W}^{(L-1)}$.\n",
    "\n",
    "Con estos reeemplazos obtenemos que:\n",
    "\n",
    "$\\frac{\\partial\\mathbf{J}}{\\partial\\mathbf{x}} =  \\frac{\\partial\\mathbf{J}}{\\partial\\mathbf{a}^{(L)}}\\left(f^{(L)}\\right)'\\mathbf{W}^{(L-1)}\\left(f^{(L-1)}\\right)'\\mathbf{W}^{(L-2)}\\ldots\\left(f^{(2)}\\right)'\\mathbf{W}^{(1)}$.\n",
    "\n",
    "Si tomamos la transpuesta de este vector columna obtenemos el vector gradiente, de esta forma:\n",
    "\n",
    "$$\\nabla_\\mathbf{x} \\mathbf{J}= \\left(\\mathbf{W}^{(1)}\\right)^{\\text{T}}\\left(f^{(2)}\\right)'\\ldots\\left(\\mathbf{W}^{(L-2)}\\right)^{\\text{T}}\\left(f^{(L-1)}\\right)'\\left(\\mathbf{W}^{(L-1)}\\right)^{\\text{T}}\\left(f^{(L)}\\right)'\\nabla_{\\mathbf{a}^{(L)}}\\mathbf{J}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora definamos una variable $\\boldsymbol\\delta^{(l)}$, la cual me definira el *error en el nivel $l$*, como:\n",
    "\n",
    "$$\\boldsymbol\\delta^{(l)} = \\left(f^{(l)}\\right)'\\left(\\mathbf{W}^{(l)}\\right)^{\\text{T}}\\ldots\\left(\\mathbf{W}^{(L-2)}\\right)^{\\text{T}}\\left(f^{(L-1)}\\right)'\\left(\\mathbf{W}^{(L-1)}\\right)^{\\text{T}}\\left(f^{(L)}\\right)'\\nabla_{\\mathbf{a}^{(L)}}\\mathbf{J}$$\n",
    "\n",
    "Note que el vector $\\boldsymbol\\delta^{(l)}$ tiene el mismo numero de elementos que neuronas en la capa $l$ (teniendo en cuenta el bias). Este termino se expresa como la propagación del error de salida hasta la capa $l$ de la red neuronal.\n",
    "\n",
    "Ahora, si deseamos obtener la derivada de la función de costo en función de los parametros $\\mathbf{W}^{(l-1)}$, entonces basta con ver que esa derivada estaría dada por:\n",
    "\n",
    "$$\\nabla_{\\mathbf{W}^{(l-1)}} \\mathbf{J}= \\nabla_{\\mathbf{z}^{(l)}} \\mathbf{J}\\frac{\\partial\\mathbf{z}^{(l)}}{\\partial\\mathbf{W}^{(l-1)}}$$\n",
    "\n",
    "Pero, \n",
    "\n",
    "$$\\nabla_{\\mathbf{z}^{(l)}} \\mathbf{J}= \\boldsymbol\\delta^{(l)}.$$\n",
    "\n",
    "Teniendo en cuenta que $\\mathbf{z}^{(l)}=\\mathbf{W}^{(l-1)}\\mathbf{a}^{(l-1)}$, entonces se tiene que:\n",
    "\n",
    "$$\\frac{\\partial\\mathbf{z}^{(l)}}{\\partial\\mathbf{W}^{(l-1)}} = \\left(\\mathbf{a}^{(l-1)}\\right)^{\\text{T}}$$\n",
    "\n",
    "Reemplazando por $\\boldsymbol\\delta^{(l)}$ y la expresion anterior, obtenemos:\n",
    "\n",
    "$$\\nabla_{\\mathbf{W}^{(l-1)}} \\mathbf{J}= \\boldsymbol\\delta^{(l)}\\left(\\mathbf{a}^{(l-1)}\\right)^{\\text{T}}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El factor $\\mathbf{a}^{(l-1)}$ indica que la influencia de los pesos $\\mathbf{W}^{(l-1)}$ en la salida esta siendo afectado por la magnitud de las funciones de activación en la capa $l-1$. De aquí s epuede observar que la propagacion del error para capas mas cercanas a la capa de entrada se puede obtener de forma recursiva por medio de la ecuación:\n",
    "\n",
    "$$\\boldsymbol\\delta^{(l-1)} = \\left(f^{(l-1)}\\right)'\\left(\\mathbf{W}^{(l-1)}\\right)^{\\text{T}}\\boldsymbol\\delta^{(l)}.$$\n",
    "\n",
    "De esta forma el gradiente de la función de costo respecto a cambios en los pesos se puede calcular con algunas multiplicaciones matriciales en cada nivel (capa), a esto se le conoce como **back-propagation**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para usar esto en el algoritmo de gradiente descendiente, la actualización de los pesos esta dada por:\n",
    "\n",
    "$$\\mathbf{W}^{(j)}:=\\mathbf{W}^{(j)}-\\eta\\nabla_{\\mathbf{W}^{(j)}}\\mathbf{J},$$\n",
    "\n",
    "donde:\n",
    "\n",
    "$$\\nabla_{\\mathbf{W}^{(j)}} \\mathbf{J}= \\boldsymbol\\delta^{(j+1)}\\left(\\mathbf{a}^{(j)}\\right)^{\\text{T}}.$$\n",
    "\n",
    "y $\\eta$ es la tasa de aprendizaje.\n",
    "\n",
    "Si $j$ es la capa de salida, se tiene que:\n",
    "\n",
    "$$\\boldsymbol\\delta^{(j+1)}= \\nabla_{\\mathbf{a}^{(j)}}\\mathbf{J}.$$\n",
    "\n",
    "Cómo $\\mathbf{a}^{(j)}$ es la salida de la red, entonces, si definimos nuestra función de costo como:\n",
    "\n",
    "$$\\mathbf{J}=\\frac{1}{2}||\\mathbf{y}-\\mathbf{a}^{(j)}||^2,$$\n",
    "\n",
    "entonces se tiene que: \n",
    "\n",
    "$$\\nabla_{\\mathbf{a}^{(j)}}\\mathbf{J}= \\mathbf{a}^{(j)}-\\mathbf{y},$$\n",
    "\n",
    "de aqui se puede obtener la actualización para los pesos en la capa inmediatamente anterior:\n",
    "\n",
    "$$\\nabla_{\\mathbf{W}^{(j-1)}} \\mathbf{J}= \\boldsymbol\\delta^{(j)}\\left(\\mathbf{a}^{(j-1)}\\right)^{\\text{T}} = \\left(\\mathbf{a}^{(j)}-\\mathbf{y}\\right)\\left(\\mathbf{a}^{(j-1)}\\right)^{\\text{T}}.$$\n",
    "\n",
    "Ahora se puede porpagar hacia atras el calculo de los $\\boldsymbol\\delta^{(j-1)}$, tal que:\n",
    "\n",
    "$$\\boldsymbol\\delta^{(j-1)} =  \\left(f^{(j-1)}\\right)'\\left(\\mathbf{W}^{(j-1)}\\right)^{\\text{T}}\\left(\\mathbf{a}^{(j)}-\\mathbf{y}\\right).$$\n",
    "\n",
    "Y una vez se calculo el error de propagación ahi si actualizamos los pesos de la capa $j-1$ usando:\n",
    "\n",
    "$$\\mathbf{W}^{(j-1)}:=\\mathbf{W}^{(j-1)}-\\eta\\nabla_{\\mathbf{W}^{(j-1)}}\\mathbf{J}.$$\n",
    "\n",
    "El proceso se repite de forma iterativa hasta llegar a la capa inicial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regla de actualización con regularización\n",
    "\n",
    "Si se incluye regularización la regla de aprendizaje y el error cuadratico medio, no solo el error medio, se tiene:\n",
    "\n",
    "$$\\mathbf{W}^{(j)}:=\\mathbf{W}^{(j)}-\\frac{\\eta}{m}\\left(\\nabla_{\\mathbf{W}^{(j)}}\\mathbf{J}-\\gamma\\mathbf{W}^{(j)}\\right),$$\n",
    "\n",
    "donde $\\gamma$ es la constante de regularización. Esto se hace para todas las columnas menos la primera (que contiene los trminos del bias (umbral), para esa columna se tiene:\n",
    "\n",
    "$$\\mathbf{W}^{(j)}:=\\mathbf{W}^{(j)}-\\frac{\\eta}{m}\\left(\\nabla_{\\mathbf{W}^{(j)}}\\mathbf{J}\\right).$$\n",
    "\n",
    "\n",
    "Es importante notar que la función de costo que s eutilizó fue par aun problema de regresión, se puede usar la función logistica y en ese caso la derivada de la función de error seria $g(x)(1-g(x))$, con $g(x)$ la función logistica.\n",
    "\n",
    "Es importante notar que backpropagation requiere que la función de activación sea derivable. Aunque aplicaciones recientes han mostrado que númericamente se puede llegar a resultados usando funciones no derivables como la *ReLu*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consideraciones al entrenar una red neuronal\n",
    "\n",
    "Cuando se entrena una red hay diferentes parámetros que se deben tener en cuenta:\n",
    "\n",
    "1. Número de capas.\n",
    "2. Número de neuronas en cada capa.\n",
    "3. Funciones de activación que se usan en cada capa.\n",
    "4. Valor de la constante de regularización.\n",
    "5. Valor de la tasa de aprendizaje.\n",
    "6. Otros valores requeridos por un algoritmo de entrenamiento diferente.\n",
    "\n",
    "Todos estos valores se consideran hyper-parámetros (parámetros que estan sobre el aprendizaje de la red). Para poder encontrar los valores adecuados de estos hyper-parámetros, se debe hacer una búsqueda. Es decir, para un conjunto de parámetros fijos, se entrena el modelo, eso produce una red neuronal a la cual le podemos medir el performance, y una vez hecho esto se procede a cambiar alguno de los parámetros y así sucesivamente. Al dfinal se escoje el conjunto de hyper-parámetros qu emejor rendimiento tengan (menor costo).\n",
    "\n",
    "Debido a que las redes neuronales se pueden considerar como aproximadores universales, ellas podrian facilmente sobreajustar lso datos, por esto se hace necesario empezar a hablar sobre como medir de forma simple el rendimiento de un modelo. Para no entrar en detalles más especificos, que cubriremos después en el curso, consideremos el siguiente procedimiento para entrenar y evaluar nuestros modelos:\n",
    "\n",
    "1. Partición de los datos: \n",
    "    * Si se tiene un problema de regresión, de las $m$ observaciones que se tienen, escoja 30% al azar y separelo de los demás (por ahora olvidemonos de esos datos).\n",
    "    * Si se tiene un problema de clasificación, por cada clase extraiga el 30% de los datos al azar y separelo de los demas (por ahora olvidemonos de esos datos).\n",
    "    * El conjunto de datos de los cuales nos olvidamos lo llamaremos **dataset de prueba**.\n",
    "    * El conjunto de datos restante lo llamaremos **dataset de entrenamiento**.\n",
    "2. Fije un conjunto de hyper-parámetros.\n",
    "3. Utilice el **dataset de entrenamiento** para entrenar el modelo (encontrar los pesos $\\mathbf{W}$ qu eminimizan la función de costo.\n",
    "4. Una vez el modelo ha sido entrenado use el **dataset de prueba** para medir cual es la predicción del modelo.\n",
    "5. use las predicciones que obtuvo para el **dataset de prueba** y calcule el rendimiento de la red. Aquí puede usar el error cuadratico medio, el porcentaje de datos correctamente clasificados, etc...\n",
    "6. Cambie el valor de lso hyper-parámetros y repita el procedimiento.\n",
    "7. Escoja el modelo que tenga una mejor medida de rendimiento.\n",
    "\n",
    "Hay varias peculariedades cuando se entrenan redes neuronales:\n",
    "\n",
    "1. Las redes se pueden ver como un mapeo nolineal de mi función a un espacio de dimensión posiblemente infinita.\n",
    "2. La dimensión del espacio de pesos de las redes puede ser muy grande, esta dado por el número de pesos de la red, y la función de costo es altamente noregular, tiene muchos picos, llanos y minimos locales.\n",
    "3. Es posible qu esi el numero de pesos es muy pequeño (pocas capas y neuronas por capa en la red) al entrenar no s etenga un buen rendimiento del gradiente descencdiente, esto debido a que posiblemente estamos ubicados en minimos locales.\n",
    "4. Por alguna razón, al aumentar la dimensionalidad del espacio de pesos, esos minimos locales y picos se trnasforman en saddle points, lo cual hace que el algoritmo converga más rápido.\n",
    "**Nota:** Teniendo en cuenta estos últimos puntos al entrenar una red se empieza por redes grandes, de muchas capas y neuronas, una vez esta red ha convergido, se eliminan ciertas neuronas de cada capa, y se vuelve a entrenar, pero se mantienen los pesos a los que convergio la red anterior. Esto hace que la inicialización de pesos se encuentre cerca del mínimo de la función de costo, y por tanto el algoritmo converge rápidanmente y evita los minimos locales. Si se empiza con redes pequeñas es posible que no se converga.\n",
    "5. La inicialización de pesos es importante, ya qu eno se conoce donde está ubicado el mínimo de la función de costo \n",
    "6. Las redes neuronales se conocen como modelos de caja negra, porque la relación entre la entrada y la salida es obscura, no se puede interpretar cual es la influencia de cada regresor. Supongamos que tenemos un modelo de regresión lineal con regresores de entrada $\\mathbf{x}=[x_1, x_2,\\ldots,x_n]$ la salida del modelo de regresión sería $y = \\theta_0 + \\theta_1x_1 + \\theta_2x_2+\\ldots+\\theta_mx_m$, aquí puedo ver exactamente la relación de cada término de entrada con la salida, teniendo cuidado con la multicolinearidad y todos esos problemas. Así tenga términos nolineales, al usar una regresión lineal puedo saber exactamente como ese término se relaciona con la slaida. Sin embargo, tengo una regresión usando redes neuronales, no es posible descomponer la salida en función de las contribuciones parciales (lienales y nolineales) de lso regresores de entrada, y de sus efectos de interacción, i.e. $x_1*x_2*x_3$. Esto es un gran problema para la interpretabilidad de los modelos, para obtener un aidea de qu eesta haciendo la red neuronal (lo cual puede servir para plantear nuevas hipotesis de relación entre variables), y principalmente para aumentar la confianza de los expertos en los diferentes campos de aplicación al usar estos modelos. Devolver la interpretabilidad a las redes es importante.\n",
    "7. Hasta hace unos 10 años las redes neuronales no eran muy populares, otros étodos como SVM o gradient boosting machines presentaban mejores resultados. Pero con el surgimiento del aprendizaje profundo esta área se popularizo, a tal punto que es hoy en día el estado del arte en los métodos de Machine Learning, ¿qué cambio?, que en lugar de utilizar redes con una cantidad pequeña de pesos, ahora se utilizan redes con millones de pesos. Por alguna razón, este cambio de paradigma, impulsado por la accesibilidad de los datos y lel aumento de la capacidad de computo, ha logrado que las redes neuronales sean muy poderosas en tareas tipicas de Machine Learning, una razón clara del porqué de esto no se conoce aún. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
