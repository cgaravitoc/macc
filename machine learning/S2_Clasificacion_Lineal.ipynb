{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Sesi√≥n 2: Clasificaci√≥n Lineal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "En esta clase estudiaremos los problemas de clasificaci√≥n lineal, particularmente LDA (Linear Discriminant Analysis) y Regresi√≥n Log√≠stica."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Pregunta:** ¬øPorqu√© no es bueno utilizar una regresi√≥n para solucionar un problema de clasificaci√≥n?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Soluci√≥n:** Cuando estudiamos regresi√≥n vimos que una de las caracter√≠sticas de la regresi√≥n lineal es que la media de los errores es cero. Esto hace que la media y la varianza de los errores se√°n independientes, lo cual es optimo en ML. Sin embargo, si utilizamos regresi√≥n en un problema de clasificaci√≥n, dado la naturaleza discreta de la(s) salida(s), la varianza en los datos de entrada va a ocasionar que el valor medio del error y la varianza esten relacionadas, tal como se muestra en las siguientes imagenes:\n",
    "\n",
    "<img src=\"img/Regresion_Clas_1.png\" width=\"400\">\n",
    "<img src=\"img/Regresion_Clas_2.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Linear Discriminant Analysis (LDA), aproximaci√≥n de Fisher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Supongamos que tenemos un conjunto de datos $\\{(\\mathbf{x}^{(1)}, y^{(1)}), (\\mathbf{x}^{(2)}, y^{(2)}), \\ldots, (\\mathbf{x}^{(m)}, y^{(m)})\\}$, donde $\\mathbf{x}^{(i)}\\in\\mathbb{R}^n$ y $y \\in\\{0,1\\}$. Sea $\\text{p}(\\mathbf{x}|y=0)$ y $\\text{p}(\\mathbf{x}|y=1)$ las distribuciones de probabilidad para los valores de $\\mathbf{x}$ que pertenecen a la clase $y = 0$ y $y=1$, respectivamente. La idea detras del LDA es tratar de encontrar la direcci√≥n de un eje, de tal forma que al proyectar $\\mathbf{x}$ sobre √©ste se maximiza la separaci√≥n entre las medias de las distribuciones de probabilidad de las variables proyectadas, y al mismo tiempo se minimizan sus varianzas. En otras palabras lo que busca LDA es realizar una transformaci√≥n lineal de los datos de entrada, tal que se maximice su dispersi√≥n entre clases, y se minimice su dispersi√≥n dentro de cada clase. La siguiente figura explica este proceso de forma grafica:\n",
    "\n",
    "<img src=\"img/LDA.png\" width=\"1000\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### ¬øC√≥mo se plantea este problema?\n",
    "\n",
    "Para solucionar este problema debemos plantear la funci√≥n de costo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pregunta:** ¬øCu√°l ser√≠a esa funci√≥n de costo?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Soluci√≥n:** Esa funci√≥n de costo se define de la siguiente forma:\n",
    "\n",
    "Sea $\\hat{y} = \\theta_0+\\boldsymbol\\theta^T\\mathbf{x}$ la salida estimada de mi modelo de clasificaci√≥n, teniendo como base esto, el valor medio de esta salida est√° dado por:\n",
    "\n",
    "$$\\begin{equation}\n",
    "\\boldsymbol\\mu_i=\\frac{1}{n_i}\\sum_{k\\in C_i}\\mathbf{x}^{(k)}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "donde $C_i$ es el conjunto de datos de entrada $\\mathbf{x}$ que pertenecen a la clase $i$, $\\mu_i$ es la media de estos elementos, y $n_i$ es el n√∫mero de muestras que pertenecen a esa clase. De esta forma, la varianza est√° dada por:\n",
    "\n",
    "$$\\begin{equation}\n",
    "\\boldsymbol\\Sigma_i=\\frac{1}{(n_i-1)}\\sum_{k\\in C_i}(\\mathbf{x}^{(k)}-\\boldsymbol\\mu_k)(\\mathbf{x}^{(k)}-\\boldsymbol\\mu_k)^\\text{T}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "donde $\\text{T}$ es la transpuesta.\n",
    "\n",
    "De aqu√≠ se puede definir la media y la varianza de los valores predichos de $y$, de forma que siendo $\\hat{y}= \\theta_0+\\boldsymbol\\theta^{\\text{T}}\\mathbf{x}$, se tiene que:\n",
    "\n",
    "$$\\begin{equation}\n",
    "\\begin{split}\n",
    "\\text{E}[\\hat{y}|\\mathbf{x}\\in C_i] & = & \\theta_0 +\\boldsymbol\\theta^{\\text{T}}\\boldsymbol\\mu_i \\\\\n",
    "\\text{Var}[\\hat{y}|\\mathbf{x}\\in C_i] &=& \\boldsymbol\\theta^{\\text{T}}\\boldsymbol\\Sigma_i\\boldsymbol\\theta\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "As√≠, asumiendo dos clases, la funci√≥n de costo es:\n",
    "\n",
    "$$\\mathbf{J}(\\boldsymbol\\theta) = \\frac{(\\boldsymbol\\mu_0^{\\text{T}}\\boldsymbol\\theta-\\boldsymbol\\mu_1^{\\text{T}}\\boldsymbol\\theta)^2}{\\left(n_0\\boldsymbol\\theta^{\\text{T}}\\boldsymbol\\Sigma_0\\boldsymbol\\theta+n_1\\boldsymbol\\theta^{\\text{T}}\\boldsymbol\\Sigma_1\\boldsymbol\\theta\\right)} = \\frac{\\left((\\boldsymbol\\mu_0^{\\text{T}}-\\boldsymbol\\mu_1^{\\text{T}})\\boldsymbol\\theta\\right)^2}{\\boldsymbol\\theta^{\\text{T}}\\left(n_0\\boldsymbol\\Sigma_0+n_1\\boldsymbol\\Sigma_1\\right)\\boldsymbol\\theta}$$\n",
    "\n",
    "En donde queremos encontrar el $\\boldsymbol\\theta := \\max\\limits_\\boldsymbol\\theta \\mathbf{J}(\\boldsymbol\\theta)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pregunta:** ¬øC√≥mo maximizar esa funci√≥n?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Soluci√≥n:** sea $\\mathbf{m}^{\\text{T}}=\\boldsymbol\\mu_0^{\\text{T}}-\\boldsymbol\\mu_1^{\\text{T}}$ y $\\mathbf{S}=n_0\\boldsymbol\\Sigma_0+n_1\\boldsymbol\\Sigma_1$, el problema se reduce a:\n",
    "\n",
    "$$\\mathbf{J}(\\boldsymbol\\theta) = \\frac{\\left(\\mathbf{m}^{\\text{T}}\\boldsymbol\\theta\\right)^2}{\\boldsymbol\\theta^{\\text{T}}\\mathbf{S}\\boldsymbol\\theta}.$$\n",
    "\n",
    "C√≥mo $\\mathbf{S}$ es una matrix simetrica, entonces $\\mathbf{S}= \\mathbf{R}^\\text{T}\\mathbf{R}$, con $\\mathbf{R}$ la raiz de $\\mathbf{S}$, y sea $\\mathbf{v} = \\mathbf{R}\\boldsymbol\\theta$, se tiene:\n",
    "\n",
    "$$\\mathbf{J}(\\boldsymbol\\theta) = \\frac{\\left(\\mathbf{m}^{\\text{T}}\\mathbf{R}^{-1}\\mathbf{v}\\right)^2}{\\mathbf{v}^{\\text{T}}\\mathbf{v}}=\\left(\\mathbf{m}^\\text{T}\\mathbf{R}^{-1}\\frac{\\mathbf{v}}{||\\mathbf{v}||}\\right)^2=\\left(\\left((\\mathbf{R}^{-1})^\\text{T}\\mathbf{m}\\right)^\\text{T}\\frac{\\mathbf{v}}{||\\mathbf{v}||}\\right)^2.$$\n",
    "\n",
    "se busca maximizar ese producto punto, el cual es m√°ximo si los dos vectores estan en la misma direcci√≥n. Propongamos que $\\mathbf{v}= a (\\mathbf{R}^{-1})^\\text{T}\\mathbf{m}$, donde $a$ es una constante, es el vector que m√°ximiza ese producto punto. Tomando de antes $\\mathbf{m} = \\boldsymbol\\mu_0-\\boldsymbol\\mu_1$, y $\\boldsymbol\\theta=\\mathbf{R}^{-1}\\mathbf{v}$ se tiene:\n",
    "\n",
    "$$ \\mathbf{v} = a\\mathbf{R}^{-1}(\\mathbf{R^{-1}})^{\\text{T}}(\\boldsymbol\\mu_0-\\boldsymbol\\mu_1)=a(\\mathbf{R}^\\text{T}\\mathbf{R})^{-1}(\\boldsymbol\\mu_0-\\boldsymbol\\mu_1),$$\n",
    "\n",
    "lo cual se simplifica por:\n",
    "\n",
    "$$\\boldsymbol\\theta = a\\mathbf{S}^{-1}(\\boldsymbol\\mu_0-\\boldsymbol\\mu_1)=a\\left(n_0\\boldsymbol\\Sigma_0+n_1\\boldsymbol\\Sigma_1\\right)^{-1}(\\boldsymbol\\mu_0-\\boldsymbol\\mu_1),$$\n",
    "\n",
    "con $a$ una constante arbitraria que puede ser 1. De all√≠:\n",
    "$$\\theta_0 = \\text{E}[y-\\boldsymbol\\theta^\\text{T}\\mathbf{x}] = \\frac{1}{n}\\sum y^{(i)}-\\boldsymbol\\theta^\\text{T}\\mathbf{x}^{(i)}.$$\n",
    "\n",
    "De forma sencilla, lo que se esta haciendo es tomar el vector de la diferencia de ambas medias, y se rota por medio de la inversa de las covarianzas de los datos, i.e. donde mas varian los datos tiene el menor efecto en esta rotaci√≥n.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nota:** LDA considera que los datos en cada clase estan distribuidos de forma Normal, y que las matrices de covarianza de las distriuciones son iguales. Fisher (tal como lo vimos aqu√≠) no requiere de easumir est√°s cosas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA a traves de Bayes\n",
    "\n",
    "Se puede llegar a LDA a traves de Bayes, sabiendo que:\n",
    "\n",
    "$$\\text{p}(y=1|\\mathbf{x})=\\frac{\\text{p}(\\mathbf{x}|y=1)\\text{p}(y=1)}{\\text{p}(\\mathbf{x})},$$\n",
    "\n",
    "donde $\\text{p}(\\mathbf{x}) = \\text{p}(\\mathbf{x}|y=1)\\text{p}(y=1)+\\text{p}(\\mathbf{x}|y=0)\\text{p}(y=0)$. En t√©rminos de probabilidades el likelihood (verosimilitud) es $\\text{p}(\\mathbf{x}|y=1)$, el prior es $\\text{p}(y=1)$ y la probabilidad marginal es $\\text{p}(\\mathbf{x})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresi√≥n Log√≠stica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La regresi√≥n log√≠stica es un metodo de clasificaci√≥n, a pesar de que se conoce como regresi√≥n. Para la clasificaci√≥n quisieramos que los valores de salida de nuestro modelo est√©n acotados entre cero (0-1) y uno. Para lograr esto, asumamos que nuestro modelo tiene la forma:\n",
    "\n",
    "$$h_{\\boldsymbol\\theta}(\\mathbf{x}) = g(\\boldsymbol\\theta^{\\text{T}}\\mathbf{x}),$$\n",
    "\n",
    "donde $g(\\displaystyle\\mathbf{z})=\\frac{1}{1+e^{-\\mathbf{z}}}$ es una funci√≥n sigmoidal o log√≠stica. Por lo tanto, la forma del modelo es:\n",
    "\n",
    "$$h_{\\boldsymbol\\theta}(\\mathbf{x}) = \\frac{1}{1+e^{-\\boldsymbol\\theta^{\\text{T}}\\mathbf{x}}}.$$\n",
    "\n",
    "La funci√≥n log√≠stica luce como se muestra en la siguiente figura:\n",
    "\n",
    "<img src=\"img/logit.png\" width=\"400\">\n",
    "\n",
    "Entonces, el problema se reduce a encontrar los valores de $\\boldsymbol\\theta$ que garantizan que se tenga una buena clasificaci√≥n. \n",
    "\n",
    "En el caso de un modelo de clasificaci√≥n para dos clases, la salida de este modelo se puede interpretar como la probabilidad de que la salida sea $y=1$ cuando la entrada es $\\mathbf{x}$, i.e. $\\text{p}(y=1|\\mathbf{x};\\boldsymbol\\theta)$. Teniendo en cuenta esto, y debido a que las probabilidades de pertenecer a una clase o la otra deben sumar uno, se tiene que $\\text{p}(y=0|\\mathbf{x};\\boldsymbol\\theta) = 1-\\text{p}(y=1|\\mathbf{x};\\boldsymbol\\theta)$.\n",
    "\n",
    "Para terminar, se puede entonces definir la salida de tal forma que:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "  \\hat{y} =\n",
    "    \\begin{cases}\n",
    "      1 & \\text{if} & h_{\\boldsymbol\\theta}(\\mathbf{x}) \\geq 0.5\\\\\n",
    "      0 & \\text{if} & h_{\\boldsymbol\\theta}(\\mathbf{x}) < 0.5\n",
    "    \\end{cases}       \n",
    "\\end{equation}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limite de Decisi√≥n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "**Pregunta:** ¬øCu√°ndo la funci√≥n logistica ser√° mayor a 0.5?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden"
   },
   "source": [
    "**Soluci√≥n:** La salida del modelo ser√° 1, i.e. $g(\\mathbf{x}) \\geq 0.5$ cuando $\\boldsymbol\\theta^\\text{T}\\mathbf{x}\\geq 0$. Si graficamos en el espacio de caracter√≠sticas, el plano donde los ejes son las variables de entrada, la ecuaci√≥n $\\boldsymbol\\theta^{\\text{T}}\\mathbf{x} = 0$, se obtiene lo que se conoce c√≥mo el l√≠mite de decisi√≥n (decision boundary), tal como muestra la siguiente figura:\n",
    "\n",
    "<img src=\"img/DesicionBoundary.png\" width=\"400\">\n",
    "\n",
    "Esta frontera de decisi√≥n separa el espacio de caracter√≠sticas en dos regiones tal que si una entrada $\\mathbf{x}$ se encuentra en una de √©stas, su salida ser√° $y=0$ o $y=1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "**Pregunta:** ¬øQu√© tipo de l√≠mite de decisi√≥n forma el modelo $h_{\\boldsymbol\\theta}(\\mathbf{x}) = g([-1;1;1]^\\text{T}[1;x_1^2;x_2^2])$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden"
   },
   "source": [
    "**Soluci√≥n:** El limite de decisi√≥n estar√≠a dado por $[‚àí1;1;1]^\\text{T}[1;ùë•_1^2;ùë•_2^2]\\geq 0$, o en otras palabras por $x_1^2+x_2^2 \\geq 1$, como se muestra en la figura de abajo. Es decir que se pueden crear fronteras no lineales, de la misma forma que en el caso de la regresion lineal. Lo importante es que este elemento del modelo sea lineal en los par√°metros $\\boldsymbol\\theta$, pero se puede hacer tan complicado como se desee eligiendo transformaciones no lineales de los regresores. \n",
    "\n",
    "<img src=\"img/NonlinearBound.png\" width=\"200\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden"
   },
   "source": [
    "**Nota:** El l√≠mite de decisi√≥n depende del modelo, no de los datos, los datos se utilizan solo para calcular los par√°metros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ajuste del modelo\n",
    "\n",
    "Sea nuestro vector $\\mathbf{x}^{(i)} = [x_0^{(i)};x_1^{(i)};\\ldots;x_n^{(i)}$, con $x_0^{(i)} = 1$, para todo $i$, y $\\mathbf{x}^{(i)} \\in \\mathbb{R}^{n+1}$ y $y\\in\\{0,1\\}$. Dado el conjunto de entrenamiento ¬øc√≥mo se encuentran los par√°metros $\\boldsymbol\\theta$?.\n",
    "\n",
    "Definamos la funci√≥n de costo para nuestra regresi√≥n:\n",
    "\n",
    "$$\\mathbf{J}(\\boldsymbol\\theta) = \\frac{1}{m}\\sum_{i=1}^{m}\\text{costo}(h_{\\boldsymbol\\theta}(\\mathbf{x}^{(i)}),y^{(i)}),$$\n",
    "\n",
    "donde $$\\text{costo}(h_{\\boldsymbol\\theta}(\\mathbf{x}^{(i)}),y^{(i)})= \\frac{1}{2}\\left(h_{\\boldsymbol\\theta}(\\mathbf{x}^{(i)})-y^{(i)}\\right)^2.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "**Pregunta:** ¬øCu√°l es el problema de esta funci√≥n de costo?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden"
   },
   "source": [
    "**Soluci√≥n:** esta funci√≥n de costo, debido al modelo de $h$ es una funci√≥n no convexa, por lo tanto el gradiente descendiente puede que no converga al m√≠nimo global. Por lo tanto hay que redefinir esta funci√≥n de costo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La nueva funci√≥n de costo para este problema es:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "  \\text{costo}(h_\\boldsymbol\\theta(\\mathbf{x}),y) =\n",
    "    \\begin{cases}\n",
    "      -\\log(h_\\boldsymbol\\theta(\\mathbf{x})) & \\text{if} & y=1\\\\\n",
    "      -log(1-h_\\boldsymbol\\theta(\\mathbf{x})) & \\text{if} & y=0\n",
    "    \\end{cases}       \n",
    "\\end{equation}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "**Pregunta:** ¬øC√≥mo luce la funci√≥n de costo de la regresi√≥n log√≠stica?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden"
   },
   "source": [
    "**Soluci√≥n:** La funci√≥n de costo luce como en la siguiente figura:\n",
    "\n",
    "<img src=\"img/Costo_Logit.png\" width=\"400\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden"
   },
   "source": [
    "Esta funci√≥n de costo garantiza que si mi predicci√≥n es correcta, es decir, $h_\\boldsymbol\\theta(\\mathbf{x}) = y$, entonces el costo es 0. Si la predicci√≥n es incorrecta, el costo tiende al $\\infty$. Adem√°s esta funci√≥n es convexa, lo cual facilita qla aplicaci√≥n del gradiente descendiente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teniendo en cuenta este nuevo costo, se obtiene que:\n",
    "\n",
    " $$ \\text{costo}(h_\\boldsymbol\\theta(\\mathbf{x}),y) = -y\\log(h_\\boldsymbol\\theta(\\mathbf{x}))-(1-y)\\log(1-h_\\boldsymbol\\theta(\\mathbf{x})).$$\n",
    " \n",
    " De all√≠ la funci√≥n de costo para la regresi√≥n log√≠stica estar√° dada por:\n",
    " \n",
    " $$\\mathbf{J}(\\boldsymbol\\theta) = -\\frac{1}{m}\\sum_{i=1}^{m}y^{(i)}\\log(h_\\boldsymbol\\theta(\\mathbf{x}^{(i)}))+(1-y^{(i)})\\log(1-h_\\boldsymbol\\theta(\\mathbf{x}^{(i)})).$$\n",
    " \n",
    "Lo √∫nico que queda por hacer es encontrar los par√°metros $\\boldsymbol\\theta$ que minimizan esa funci√≥n de costo. Para hacer esto se utiliza el gradiente descendiente.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "shown",
    "solution2_first": true
   },
   "source": [
    "**Pregunta:** ¬øQu√© necesitamos para poder desarrollar el gradiente descendiente?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "shown"
   },
   "source": [
    "**Soluci√≥n:** Para implementar el algoritmo, necesitamos encontrar la derivada de la funci√≥n de costo en funci√≥n de los par√°metros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "shown",
    "solution2_first": true
   },
   "source": [
    "**Pregunta:** ¬øCu√°nto da la derivada de la funci√≥n de costo en funci√≥n de los par√°metros?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "shown"
   },
   "source": [
    "**Soluci√≥n:** La derivada tiene como resultado:\n",
    "\n",
    "$$\\frac{\\partial\\mathbf{J}(\\boldsymbol\\theta)}{\\partial\\theta_j} = \\frac{1}{m}\\sum_{i=1}^m\\left(h_\\boldsymbol\\theta(\\mathbf{x}^{(i)})-y^{(i)}\\right)x_j^{(i)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "shown",
    "solution2_first": true
   },
   "source": [
    "**Pregunta:** ¬øC√≥mo es la regla de actualizaci√≥n del gradiente descendiente para la regresi√≥n log√≠stica?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "shown"
   },
   "source": [
    "As√≠, la regla de actualizaci√≥n de los pesos en el gradiente descendiente, para la regresi√≥n logistica, esta dada por:\n",
    "\n",
    "$$ \\begin{equation}\n",
    "      \\theta_n := \\theta_n-\\alpha\\frac{1}{m}\\sum_{i=1}^{m}\\left[h_\\boldsymbol\\theta(\\mathbf{x}^{(i)})-y^{(i)}\\right]x_n^{(i)}\\\\\n",
    "   \\end{equation}$$\n",
    "   \n",
    "Donde $x_0^{(i)}= 1$ para todo $i$. Aunque parece id√©ntica al gradiente descendiente para regresi√≥n lineal, no lo es, ya que la funci√≥n $h_\\boldsymbol\\theta(\\mathbf{x})$ es diferente a la funci√≥n de regresi√≥n lineal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "shown"
   },
   "source": [
    "**Nota 1:** La normalizaci√≥n de caracter√≠sticas (regresores) tambi√©n aplica para el gradiente descendiente cuando se usa la regresi√≥n log√≠stica, de la misma forma que se aplica para regresion lineal.\n",
    "\n",
    "**Nota 2:** Aparte del gradiente descendiente existen otros algoritmos m√°s sofisticados que permiten encontrar los par√°metros que minimizan la funci√≥n de costo. Generalmente ellos requieren una funci√≥n para el c√°lculo del costo y  su derivada en funci√≥n de los par√°metros. Adem√°s, estos son m√°s r√°pidos y no requieren sintonizar la tasa de aprendizaje, pero por otro lado son m√©todos m√°s complicados. Estos algoritmos no se estudiaran en el curso, debieron verse en Optimizaci√≥n, (Conjugate gradient, BFGS, L-BGFS)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresi√≥n Logistica Multiclase\n",
    "\n",
    "Si se tienen $p$ clases, se pueden entrenar $p$ clasificadores, utilizando regresi√≥n log√≠stica, y al final se agregan las salidas de cada clasificador, de tal forma que para la clase seleccionada se escoge aquella que tenga la mayor probabilidad (la mayor variable latente de salida del clasificador). Tal como se explica en la figura:\n",
    "\n",
    "<img src=\"img/onevsrest.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "**Pregunta:** ¬øQu√© sucede si no se selecciona al final, la clase que de la mayor probabilidad, sino que se selecciona la clase en funci√≥n de si la probabilidad es mayor a 0.5?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden"
   },
   "source": [
    "**Soluci√≥n:** si se realiza de esta forma la asignaci√≥n de la clase se puede crear una regi√≥n de ambig√ºedad, tal como se muestra en la figura de abajo:\n",
    "\n",
    "<img src=\"img/Ambiguedad.png\" width=\"200\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matem√°ticamente, la salida del clasificador est√° dada por: \n",
    "\n",
    "$$\\hat{y} = \\max\\limits_ih^{(i)}_\\boldsymbol\\theta(\\mathbf{x}),$$\n",
    "\n",
    "donde $h^{(i)}_\\boldsymbol\\theta(\\mathbf{x})$ es la salida del clasificador entrenado para la clase $i$.\n",
    "\n",
    "Otra estrategia es combinar las variables latentes (antes de aplicar la funci√≥n logistica) a una funci√≥n tipo softmax, aunque esto no es generalmente conocido como regresi√≥n log√≠stica:\n",
    "\n",
    "$$\\sigma(\\mathbf{z})_j=\\frac{e^{z_j}}{\\sum_{k=1}^pe^{z_k}},$$\n",
    "\n",
    "donde $z_k=\\boldsymbol\\theta_k^\\text{T}\\mathbf{x}$, para $k=\\{1,\\ldots,p\\}$ y $\\mathbf{z}=[z_1,\\ldots,z_p]^\\text{T}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularizaci√≥n en Regresi√≥n Log√≠stica\n",
    "\n",
    "La regresi√≥n log√≠stica puede tambien llegar a estar sobre-ajustada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "**Pregunta:** ¬øQu√© significa que la regresi√≥n logistica pueda estar sobre-ajustada? ¬øC√≥mo luce un clasificador sobreajustado?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden"
   },
   "source": [
    "**Soluci√≥n:** Un clasificador sobreajustado genera l√≠mites de decisi√≥n extremadamente complicados, no suaves, que no son capaces de generalizar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para evitar el sobreajuste en la regresi√≥n log√≠stica, podemos usar el mismo criterio que en regresi√≥n lineal,  es decir, disminuir el n√∫mero de regresores, o utilizar regularizaci√≥n, tipo LASSO, RIDGE, Tickhonov, etc. De est√° forma, la nueva funci√≥n de costo ser√°:\n",
    "\n",
    " $$\\mathbf{J}(\\boldsymbol\\theta) = -\\frac{1}{m}\\sum_{i=1}^{m}y^{(i)}\\log(h_\\boldsymbol\\theta(\\mathbf{x}^{(i)}))+(1-y^{(i)})\\log(1-h_\\boldsymbol\\theta(\\mathbf{x}^{(i)}))+\\frac{\\gamma}{2m}\\sum_{j=1}^n\\theta_j^2.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "**Pregunta:** ¬øC√≥mo es la regla de actualizaci√≥n del gradiente descendiente para el tipo de regularizaci√≥n anterior (norma L2)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden"
   },
   "source": [
    "La actualizaci√≥n en gradiente descendiente en este caso es:\n",
    "\n",
    "$$ \\begin{equation}\n",
    "\\begin{split}\n",
    "    \\theta_0&:=& \\theta_0-\\alpha\\frac{1}{m}\\sum_{i=1}^{m}\\left[h_\\boldsymbol\\theta(\\mathbf{x}^{(i)})-y^{(i)}\\right]x_0^{(i)}\\\\\n",
    "\\theta_j &:=& \\theta_n-\\alpha\\left[\\frac{1}{m}\\sum_{i=1}^{m}\\left[h_\\boldsymbol\\theta(\\mathbf{x}^{(i)})-y^{(i)}\\right]x_j^{(i)}+\\frac{\\gamma}{m}\\theta_j\\right]\\\\\n",
    "\\end{split}\n",
    "\\end{equation}$$\n",
    "\n",
    "con $j={1,\\ldots,n}$. Donde el modelo $h_\\boldsymbol\\theta(\\mathbf{x})$ es la funci√≥n logistica."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
