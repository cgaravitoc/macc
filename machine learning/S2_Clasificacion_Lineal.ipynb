{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Sesión 2: Clasificación Lineal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "En esta clase estudiaremos los problemas de clasificación lineal, particularmente LDA (Linear Discriminant Analysis) y Regresión Logística."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Pregunta:** ¿Porqué no es bueno utilizar una regresión para solucionar un problema de clasificación?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solución:** Cuando estudiamos regresión vimos que una de las características de la regresión lineal es que la media de los errores es cero. Esto hace que la media y la varianza de los errores seán independientes, lo cual es optimo en ML. Sin embargo, si utilizamos regresión en un problema de clasificación, dado la naturaleza discreta de la(s) salida(s), la varianza en los datos de entrada va a ocasionar que el valor medio del error y la varianza esten relacionadas, tal como se muestra en las siguientes imagenes:\n",
    "\n",
    "<img src=\"img/Regresion_Clas_1.png\" width=\"400\">\n",
    "<img src=\"img/Regresion_Clas_2.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Linear Discriminant Analysis (LDA), aproximación de Fisher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Supongamos que tenemos un conjunto de datos $\\{(\\mathbf{x}^{(1)}, y^{(1)}), (\\mathbf{x}^{(2)}, y^{(2)}), \\ldots, (\\mathbf{x}^{(m)}, y^{(m)})\\}$, donde $\\mathbf{x}^{(i)}\\in\\mathbb{R}^n$ y $y \\in\\{0,1\\}$. Sea $\\text{p}(\\mathbf{x}|y=0)$ y $\\text{p}(\\mathbf{x}|y=1)$ las distribuciones de probabilidad para los valores de $\\mathbf{x}$ que pertenecen a la clase $y = 0$ y $y=1$, respectivamente. La idea detras del LDA es tratar de encontrar la dirección de un eje, de tal forma que al proyectar $\\mathbf{x}$ sobre éste se maximiza la separación entre las medias de las distribuciones de probabilidad de las variables proyectadas, y al mismo tiempo se minimizan sus varianzas. En otras palabras lo que busca LDA es realizar una transformación lineal de los datos de entrada, tal que se maximice su dispersión entre clases, y se minimice su dispersión dentro de cada clase. La siguiente figura explica este proceso de forma grafica:\n",
    "\n",
    "<img src=\"img/LDA.png\" width=\"1000\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### ¿Cómo se plantea este problema?\n",
    "\n",
    "Para solucionar este problema debemos plantear la función de costo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pregunta:** ¿Cuál sería esa función de costo?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solución:** Esa función de costo se define de la siguiente forma:\n",
    "\n",
    "Sea $\\hat{y} = \\theta_0+\\boldsymbol\\theta^T\\mathbf{x}$ la salida estimada de mi modelo de clasificación, teniendo como base esto, el valor medio de esta salida está dado por:\n",
    "\n",
    "$$\\begin{equation}\n",
    "\\boldsymbol\\mu_i=\\frac{1}{n_i}\\sum_{k\\in C_i}\\mathbf{x}^{(k)}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "donde $C_i$ es el conjunto de datos de entrada $\\mathbf{x}$ que pertenecen a la clase $i$, $\\mu_i$ es la media de estos elementos, y $n_i$ es el número de muestras que pertenecen a esa clase. De esta forma, la varianza está dada por:\n",
    "\n",
    "$$\\begin{equation}\n",
    "\\boldsymbol\\Sigma_i=\\frac{1}{(n_i-1)}\\sum_{k\\in C_i}(\\mathbf{x}^{(k)}-\\boldsymbol\\mu_k)(\\mathbf{x}^{(k)}-\\boldsymbol\\mu_k)^\\text{T}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "donde $\\text{T}$ es la transpuesta.\n",
    "\n",
    "De aquí se puede definir la media y la varianza de los valores predichos de $y$, de forma que siendo $\\hat{y}= \\theta_0+\\boldsymbol\\theta^{\\text{T}}\\mathbf{x}$, se tiene que:\n",
    "\n",
    "$$\\begin{equation}\n",
    "\\begin{split}\n",
    "\\text{E}[\\hat{y}|\\mathbf{x}\\in C_i] & = & \\theta_0 +\\boldsymbol\\theta^{\\text{T}}\\boldsymbol\\mu_i \\\\\n",
    "\\text{Var}[\\hat{y}|\\mathbf{x}\\in C_i] &=& \\boldsymbol\\theta^{\\text{T}}\\boldsymbol\\Sigma_i\\boldsymbol\\theta\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "Así, asumiendo dos clases, la función de costo es:\n",
    "\n",
    "$$\\mathbf{J}(\\boldsymbol\\theta) = \\frac{(\\boldsymbol\\mu_0^{\\text{T}}\\boldsymbol\\theta-\\boldsymbol\\mu_1^{\\text{T}}\\boldsymbol\\theta)^2}{\\left(n_0\\boldsymbol\\theta^{\\text{T}}\\boldsymbol\\Sigma_0\\boldsymbol\\theta+n_1\\boldsymbol\\theta^{\\text{T}}\\boldsymbol\\Sigma_1\\boldsymbol\\theta\\right)} = \\frac{\\left((\\boldsymbol\\mu_0^{\\text{T}}-\\boldsymbol\\mu_1^{\\text{T}})\\boldsymbol\\theta\\right)^2}{\\boldsymbol\\theta^{\\text{T}}\\left(n_0\\boldsymbol\\Sigma_0+n_1\\boldsymbol\\Sigma_1\\right)\\boldsymbol\\theta}$$\n",
    "\n",
    "En donde queremos encontrar el $\\boldsymbol\\theta := \\max\\limits_\\boldsymbol\\theta \\mathbf{J}(\\boldsymbol\\theta)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pregunta:** ¿Cómo maximizar esa función?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solución:** sea $\\mathbf{m}^{\\text{T}}=\\boldsymbol\\mu_0^{\\text{T}}-\\boldsymbol\\mu_1^{\\text{T}}$ y $\\mathbf{S}=n_0\\boldsymbol\\Sigma_0+n_1\\boldsymbol\\Sigma_1$, el problema se reduce a:\n",
    "\n",
    "$$\\mathbf{J}(\\boldsymbol\\theta) = \\frac{\\left(\\mathbf{m}^{\\text{T}}\\boldsymbol\\theta\\right)^2}{\\boldsymbol\\theta^{\\text{T}}\\mathbf{S}\\boldsymbol\\theta}.$$\n",
    "\n",
    "Cómo $\\mathbf{S}$ es una matrix simetrica, entonces $\\mathbf{S}= \\mathbf{R}^\\text{T}\\mathbf{R}$, con $\\mathbf{R}$ la raiz de $\\mathbf{S}$, y sea $\\mathbf{v} = \\mathbf{R}\\boldsymbol\\theta$, se tiene:\n",
    "\n",
    "$$\\mathbf{J}(\\boldsymbol\\theta) = \\frac{\\left(\\mathbf{m}^{\\text{T}}\\mathbf{R}^{-1}\\mathbf{v}\\right)^2}{\\mathbf{v}^{\\text{T}}\\mathbf{v}}=\\left(\\mathbf{m}^\\text{T}\\mathbf{R}^{-1}\\frac{\\mathbf{v}}{||\\mathbf{v}||}\\right)^2=\\left(\\left((\\mathbf{R}^{-1})^\\text{T}\\mathbf{m}\\right)^\\text{T}\\frac{\\mathbf{v}}{||\\mathbf{v}||}\\right)^2.$$\n",
    "\n",
    "se busca maximizar ese producto punto, el cual es máximo si los dos vectores estan en la misma dirección. Propongamos que $\\mathbf{v}= a (\\mathbf{R}^{-1})^\\text{T}\\mathbf{m}$, donde $a$ es una constante, es el vector que máximiza ese producto punto. Tomando de antes $\\mathbf{m} = \\boldsymbol\\mu_0-\\boldsymbol\\mu_1$, y $\\boldsymbol\\theta=\\mathbf{R}^{-1}\\mathbf{v}$ se tiene:\n",
    "\n",
    "$$ \\mathbf{v} = a\\mathbf{R}^{-1}(\\mathbf{R^{-1}})^{\\text{T}}(\\boldsymbol\\mu_0-\\boldsymbol\\mu_1)=a(\\mathbf{R}^\\text{T}\\mathbf{R})^{-1}(\\boldsymbol\\mu_0-\\boldsymbol\\mu_1),$$\n",
    "\n",
    "lo cual se simplifica por:\n",
    "\n",
    "$$\\boldsymbol\\theta = a\\mathbf{S}^{-1}(\\boldsymbol\\mu_0-\\boldsymbol\\mu_1)=a\\left(n_0\\boldsymbol\\Sigma_0+n_1\\boldsymbol\\Sigma_1\\right)^{-1}(\\boldsymbol\\mu_0-\\boldsymbol\\mu_1),$$\n",
    "\n",
    "con $a$ una constante arbitraria que puede ser 1. De allí:\n",
    "$$\\theta_0 = \\text{E}[y-\\boldsymbol\\theta^\\text{T}\\mathbf{x}] = \\frac{1}{n}\\sum y^{(i)}-\\boldsymbol\\theta^\\text{T}\\mathbf{x}^{(i)}.$$\n",
    "\n",
    "De forma sencilla, lo que se esta haciendo es tomar el vector de la diferencia de ambas medias, y se rota por medio de la inversa de las covarianzas de los datos, i.e. donde mas varian los datos tiene el menor efecto en esta rotación.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nota:** LDA considera que los datos en cada clase estan distribuidos de forma Normal, y que las matrices de covarianza de las distriuciones son iguales. Fisher (tal como lo vimos aquí) no requiere de easumir estás cosas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA a traves de Bayes\n",
    "\n",
    "Se puede llegar a LDA a traves de Bayes, sabiendo que:\n",
    "\n",
    "$$\\text{p}(y=1|\\mathbf{x})=\\frac{\\text{p}(\\mathbf{x}|y=1)\\text{p}(y=1)}{\\text{p}(\\mathbf{x})},$$\n",
    "\n",
    "donde $\\text{p}(\\mathbf{x}) = \\text{p}(\\mathbf{x}|y=1)\\text{p}(y=1)+\\text{p}(\\mathbf{x}|y=0)\\text{p}(y=0)$. En términos de probabilidades el likelihood (verosimilitud) es $\\text{p}(\\mathbf{x}|y=1)$, el prior es $\\text{p}(y=1)$ y la probabilidad marginal es $\\text{p}(\\mathbf{x})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresión Logística"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La regresión logística es un metodo de clasificación, a pesar de que se conoce como regresión. Para la clasificación quisieramos que los valores de salida de nuestro modelo estén acotados entre cero (0-1) y uno. Para lograr esto, asumamos que nuestro modelo tiene la forma:\n",
    "\n",
    "$$h_{\\boldsymbol\\theta}(\\mathbf{x}) = g(\\boldsymbol\\theta^{\\text{T}}\\mathbf{x}),$$\n",
    "\n",
    "donde $g(\\displaystyle\\mathbf{z})=\\frac{1}{1+e^{-\\mathbf{z}}}$ es una función sigmoidal o logística. Por lo tanto, la forma del modelo es:\n",
    "\n",
    "$$h_{\\boldsymbol\\theta}(\\mathbf{x}) = \\frac{1}{1+e^{-\\boldsymbol\\theta^{\\text{T}}\\mathbf{x}}}.$$\n",
    "\n",
    "La función logística luce como se muestra en la siguiente figura:\n",
    "\n",
    "<img src=\"img/logit.png\" width=\"400\">\n",
    "\n",
    "Entonces, el problema se reduce a encontrar los valores de $\\boldsymbol\\theta$ que garantizan que se tenga una buena clasificación. \n",
    "\n",
    "En el caso de un modelo de clasificación para dos clases, la salida de este modelo se puede interpretar como la probabilidad de que la salida sea $y=1$ cuando la entrada es $\\mathbf{x}$, i.e. $\\text{p}(y=1|\\mathbf{x};\\boldsymbol\\theta)$. Teniendo en cuenta esto, y debido a que las probabilidades de pertenecer a una clase o la otra deben sumar uno, se tiene que $\\text{p}(y=0|\\mathbf{x};\\boldsymbol\\theta) = 1-\\text{p}(y=1|\\mathbf{x};\\boldsymbol\\theta)$.\n",
    "\n",
    "Para terminar, se puede entonces definir la salida de tal forma que:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "  \\hat{y} =\n",
    "    \\begin{cases}\n",
    "      1 & \\text{if} & h_{\\boldsymbol\\theta}(\\mathbf{x}) \\geq 0.5\\\\\n",
    "      0 & \\text{if} & h_{\\boldsymbol\\theta}(\\mathbf{x}) < 0.5\n",
    "    \\end{cases}       \n",
    "\\end{equation}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limite de Decisión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "**Pregunta:** ¿Cuándo la función logistica será mayor a 0.5?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden"
   },
   "source": [
    "**Solución:** La salida del modelo será 1, i.e. $g(\\mathbf{x}) \\geq 0.5$ cuando $\\boldsymbol\\theta^\\text{T}\\mathbf{x}\\geq 0$. Si graficamos en el espacio de características, el plano donde los ejes son las variables de entrada, la ecuación $\\boldsymbol\\theta^{\\text{T}}\\mathbf{x} = 0$, se obtiene lo que se conoce cómo el límite de decisión (decision boundary), tal como muestra la siguiente figura:\n",
    "\n",
    "<img src=\"img/DesicionBoundary.png\" width=\"400\">\n",
    "\n",
    "Esta frontera de decisión separa el espacio de características en dos regiones tal que si una entrada $\\mathbf{x}$ se encuentra en una de éstas, su salida será $y=0$ o $y=1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "**Pregunta:** ¿Qué tipo de límite de decisión forma el modelo $h_{\\boldsymbol\\theta}(\\mathbf{x}) = g([-1;1;1]^\\text{T}[1;x_1^2;x_2^2])$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden"
   },
   "source": [
    "**Solución:** El limite de decisión estaría dado por $[−1;1;1]^\\text{T}[1;𝑥_1^2;𝑥_2^2]\\geq 0$, o en otras palabras por $x_1^2+x_2^2 \\geq 1$, como se muestra en la figura de abajo. Es decir que se pueden crear fronteras no lineales, de la misma forma que en el caso de la regresion lineal. Lo importante es que este elemento del modelo sea lineal en los parámetros $\\boldsymbol\\theta$, pero se puede hacer tan complicado como se desee eligiendo transformaciones no lineales de los regresores. \n",
    "\n",
    "<img src=\"img/NonlinearBound.png\" width=\"200\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden"
   },
   "source": [
    "**Nota:** El límite de decisión depende del modelo, no de los datos, los datos se utilizan solo para calcular los parámetros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ajuste del modelo\n",
    "\n",
    "Sea nuestro vector $\\mathbf{x}^{(i)} = [x_0^{(i)};x_1^{(i)};\\ldots;x_n^{(i)}$, con $x_0^{(i)} = 1$, para todo $i$, y $\\mathbf{x}^{(i)} \\in \\mathbb{R}^{n+1}$ y $y\\in\\{0,1\\}$. Dado el conjunto de entrenamiento ¿cómo se encuentran los parámetros $\\boldsymbol\\theta$?.\n",
    "\n",
    "Definamos la función de costo para nuestra regresión:\n",
    "\n",
    "$$\\mathbf{J}(\\boldsymbol\\theta) = \\frac{1}{m}\\sum_{i=1}^{m}\\text{costo}(h_{\\boldsymbol\\theta}(\\mathbf{x}^{(i)}),y^{(i)}),$$\n",
    "\n",
    "donde $$\\text{costo}(h_{\\boldsymbol\\theta}(\\mathbf{x}^{(i)}),y^{(i)})= \\frac{1}{2}\\left(h_{\\boldsymbol\\theta}(\\mathbf{x}^{(i)})-y^{(i)}\\right)^2.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "**Pregunta:** ¿Cuál es el problema de esta función de costo?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden"
   },
   "source": [
    "**Solución:** esta función de costo, debido al modelo de $h$ es una función no convexa, por lo tanto el gradiente descendiente puede que no converga al mínimo global. Por lo tanto hay que redefinir esta función de costo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La nueva función de costo para este problema es:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "  \\text{costo}(h_\\boldsymbol\\theta(\\mathbf{x}),y) =\n",
    "    \\begin{cases}\n",
    "      -\\log(h_\\boldsymbol\\theta(\\mathbf{x})) & \\text{if} & y=1\\\\\n",
    "      -log(1-h_\\boldsymbol\\theta(\\mathbf{x})) & \\text{if} & y=0\n",
    "    \\end{cases}       \n",
    "\\end{equation}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "**Pregunta:** ¿Cómo luce la función de costo de la regresión logística?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden"
   },
   "source": [
    "**Solución:** La función de costo luce como en la siguiente figura:\n",
    "\n",
    "<img src=\"img/Costo_Logit.png\" width=\"400\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden"
   },
   "source": [
    "Esta función de costo garantiza que si mi predicción es correcta, es decir, $h_\\boldsymbol\\theta(\\mathbf{x}) = y$, entonces el costo es 0. Si la predicción es incorrecta, el costo tiende al $\\infty$. Además esta función es convexa, lo cual facilita qla aplicación del gradiente descendiente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teniendo en cuenta este nuevo costo, se obtiene que:\n",
    "\n",
    " $$ \\text{costo}(h_\\boldsymbol\\theta(\\mathbf{x}),y) = -y\\log(h_\\boldsymbol\\theta(\\mathbf{x}))-(1-y)\\log(1-h_\\boldsymbol\\theta(\\mathbf{x})).$$\n",
    " \n",
    " De allí la función de costo para la regresión logística estará dada por:\n",
    " \n",
    " $$\\mathbf{J}(\\boldsymbol\\theta) = -\\frac{1}{m}\\sum_{i=1}^{m}y^{(i)}\\log(h_\\boldsymbol\\theta(\\mathbf{x}^{(i)}))+(1-y^{(i)})\\log(1-h_\\boldsymbol\\theta(\\mathbf{x}^{(i)})).$$\n",
    " \n",
    "Lo único que queda por hacer es encontrar los parámetros $\\boldsymbol\\theta$ que minimizan esa función de costo. Para hacer esto se utiliza el gradiente descendiente.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "shown",
    "solution2_first": true
   },
   "source": [
    "**Pregunta:** ¿Qué necesitamos para poder desarrollar el gradiente descendiente?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "shown"
   },
   "source": [
    "**Solución:** Para implementar el algoritmo, necesitamos encontrar la derivada de la función de costo en función de los parámetros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "shown",
    "solution2_first": true
   },
   "source": [
    "**Pregunta:** ¿Cuánto da la derivada de la función de costo en función de los parámetros?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "shown"
   },
   "source": [
    "**Solución:** La derivada tiene como resultado:\n",
    "\n",
    "$$\\frac{\\partial\\mathbf{J}(\\boldsymbol\\theta)}{\\partial\\theta_j} = \\frac{1}{m}\\sum_{i=1}^m\\left(h_\\boldsymbol\\theta(\\mathbf{x}^{(i)})-y^{(i)}\\right)x_j^{(i)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "shown",
    "solution2_first": true
   },
   "source": [
    "**Pregunta:** ¿Cómo es la regla de actualización del gradiente descendiente para la regresión logística?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "shown"
   },
   "source": [
    "Así, la regla de actualización de los pesos en el gradiente descendiente, para la regresión logistica, esta dada por:\n",
    "\n",
    "$$ \\begin{equation}\n",
    "      \\theta_n := \\theta_n-\\alpha\\frac{1}{m}\\sum_{i=1}^{m}\\left[h_\\boldsymbol\\theta(\\mathbf{x}^{(i)})-y^{(i)}\\right]x_n^{(i)}\\\\\n",
    "   \\end{equation}$$\n",
    "   \n",
    "Donde $x_0^{(i)}= 1$ para todo $i$. Aunque parece idéntica al gradiente descendiente para regresión lineal, no lo es, ya que la función $h_\\boldsymbol\\theta(\\mathbf{x})$ es diferente a la función de regresión lineal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "shown"
   },
   "source": [
    "**Nota 1:** La normalización de características (regresores) también aplica para el gradiente descendiente cuando se usa la regresión logística, de la misma forma que se aplica para regresion lineal.\n",
    "\n",
    "**Nota 2:** Aparte del gradiente descendiente existen otros algoritmos más sofisticados que permiten encontrar los parámetros que minimizan la función de costo. Generalmente ellos requieren una función para el cálculo del costo y  su derivada en función de los parámetros. Además, estos son más rápidos y no requieren sintonizar la tasa de aprendizaje, pero por otro lado son métodos más complicados. Estos algoritmos no se estudiaran en el curso, debieron verse en Optimización, (Conjugate gradient, BFGS, L-BGFS)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresión Logistica Multiclase\n",
    "\n",
    "Si se tienen $p$ clases, se pueden entrenar $p$ clasificadores, utilizando regresión logística, y al final se agregan las salidas de cada clasificador, de tal forma que para la clase seleccionada se escoge aquella que tenga la mayor probabilidad (la mayor variable latente de salida del clasificador). Tal como se explica en la figura:\n",
    "\n",
    "<img src=\"img/onevsrest.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "**Pregunta:** ¿Qué sucede si no se selecciona al final, la clase que de la mayor probabilidad, sino que se selecciona la clase en función de si la probabilidad es mayor a 0.5?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden"
   },
   "source": [
    "**Solución:** si se realiza de esta forma la asignación de la clase se puede crear una región de ambigüedad, tal como se muestra en la figura de abajo:\n",
    "\n",
    "<img src=\"img/Ambiguedad.png\" width=\"200\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matemáticamente, la salida del clasificador está dada por: \n",
    "\n",
    "$$\\hat{y} = \\max\\limits_ih^{(i)}_\\boldsymbol\\theta(\\mathbf{x}),$$\n",
    "\n",
    "donde $h^{(i)}_\\boldsymbol\\theta(\\mathbf{x})$ es la salida del clasificador entrenado para la clase $i$.\n",
    "\n",
    "Otra estrategia es combinar las variables latentes (antes de aplicar la función logistica) a una función tipo softmax, aunque esto no es generalmente conocido como regresión logística:\n",
    "\n",
    "$$\\sigma(\\mathbf{z})_j=\\frac{e^{z_j}}{\\sum_{k=1}^pe^{z_k}},$$\n",
    "\n",
    "donde $z_k=\\boldsymbol\\theta_k^\\text{T}\\mathbf{x}$, para $k=\\{1,\\ldots,p\\}$ y $\\mathbf{z}=[z_1,\\ldots,z_p]^\\text{T}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularización en Regresión Logística\n",
    "\n",
    "La regresión logística puede tambien llegar a estar sobre-ajustada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "**Pregunta:** ¿Qué significa que la regresión logistica pueda estar sobre-ajustada? ¿Cómo luce un clasificador sobreajustado?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden"
   },
   "source": [
    "**Solución:** Un clasificador sobreajustado genera límites de decisión extremadamente complicados, no suaves, que no son capaces de generalizar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para evitar el sobreajuste en la regresión logística, podemos usar el mismo criterio que en regresión lineal,  es decir, disminuir el número de regresores, o utilizar regularización, tipo LASSO, RIDGE, Tickhonov, etc. De está forma, la nueva función de costo será:\n",
    "\n",
    " $$\\mathbf{J}(\\boldsymbol\\theta) = -\\frac{1}{m}\\sum_{i=1}^{m}y^{(i)}\\log(h_\\boldsymbol\\theta(\\mathbf{x}^{(i)}))+(1-y^{(i)})\\log(1-h_\\boldsymbol\\theta(\\mathbf{x}^{(i)}))+\\frac{\\gamma}{2m}\\sum_{j=1}^n\\theta_j^2.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "**Pregunta:** ¿Cómo es la regla de actualización del gradiente descendiente para el tipo de regularización anterior (norma L2)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden"
   },
   "source": [
    "La actualización en gradiente descendiente en este caso es:\n",
    "\n",
    "$$ \\begin{equation}\n",
    "\\begin{split}\n",
    "    \\theta_0&:=& \\theta_0-\\alpha\\frac{1}{m}\\sum_{i=1}^{m}\\left[h_\\boldsymbol\\theta(\\mathbf{x}^{(i)})-y^{(i)}\\right]x_0^{(i)}\\\\\n",
    "\\theta_j &:=& \\theta_n-\\alpha\\left[\\frac{1}{m}\\sum_{i=1}^{m}\\left[h_\\boldsymbol\\theta(\\mathbf{x}^{(i)})-y^{(i)}\\right]x_j^{(i)}+\\frac{\\gamma}{m}\\theta_j\\right]\\\\\n",
    "\\end{split}\n",
    "\\end{equation}$$\n",
    "\n",
    "con $j={1,\\ldots,n}$. Donde el modelo $h_\\boldsymbol\\theta(\\mathbf{x})$ es la función logistica."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
