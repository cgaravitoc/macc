{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto I\n",
    "\n",
    "El objetivo en este problema de regresión es construir un modelo para predecir el precio de una casa en boston. Los datos se pueden cargar de los dataset que se encuentran en la libreria scikit-learn de python. Para solucionar realice las siguientes tareas:\n",
    "\n",
    "1. Cargen los datos *boston* de la librería scikit learn.\n",
    "2. Piensen como deberia ser el problema de regresión, formule el problema y aplique una regresion lineal multivariable normal, y una regularizada.\n",
    "3. Modifique la matriz de regresores para obtener una estimación no lineal del precio de las casas. ¿Es necesario hacer esto?\n",
    "4. Implemente una regresión utilizando LASSO.\n",
    "\n",
    "Como el objetivo es evaluar sus conocimientos deben responder las siguientes preguntas:\n",
    "\n",
    "1. ¿Qué modificación le hizó a la matriz de regresores? ¿Porqué hizó esos cambios?\n",
    "2. ¿Que diferencias encuentra entre la regresión regularizada y la no regularizada?, ¿Cuál es mejor en su opinió? ¿Porqué?\n",
    "3. ¿Cómo son los resultados proporcionados por LASSO, comparados con los que obtuvo con la regresion regularizada?\n",
    "4. ¿Qué mejoras le haría al algoritmo? ¿Es un modelo lineal suficiente para solucionar este problema?\n",
    "5. ¿Qué puede concluir si observa lso valores de los parámetros $\\theta$? ¿Es bueno analizar directamente estos valores?\n",
    "6. ¿Qué puede concluir al final de este proyecto?, escriba su opinión frente a los metodos de regresión y como se aplicó en este proyecto.\n",
    "\n",
    "Deben realizar su proyecto en grupos de 3 o 4 alumnos, y entregar un notebook de jupyter con el código documentado con el análisis de cada una de las partes, es decir una explicación de que hace en cada parte del código; además, deben incluir las respuestas a las preguntas realizadas. Al entregar el notebook, por favor use la convención Nombre1__Apellido1_Regresión_1_ML.\n",
    "\n",
    "**Nota:** Si las respuestas no son claras, o si su procedimiento nos está justificado, no se tendrá en cuenta. No olviden sus referencias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cargar datos de *Boston*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.linalg import pinv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load Boston data set\n",
    "'''\n",
    "    The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
    "    prices and the demand for clean air', J. Environ. Economics & Management,\n",
    "    vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
    "    ...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
    "    pages 244-261 of the latter.\n",
    "\n",
    "    Variables in order:\n",
    "    CRIM     per capita crime rate by town\n",
    "    ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
    "    INDUS    proportion of non-retail business acres per town\n",
    "    CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
    "    NOX      nitric oxides concentration (parts per 10 million)\n",
    "    RM       average number of rooms per dwelling\n",
    "    AGE      proportion of owner-occupied units built prior to 1940\n",
    "    DIS      weighted distances to five Boston employment centres\n",
    "    RAD      index of accessibility to radial highways\n",
    "    TAX      full-value property-tax rate per $10,000\n",
    "    PTRATIO  pupil-teacher ratio by town\n",
    "    B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
    "    LSTAT    % lower status of the population\n",
    "    MEDV     Median value of owner-occupied homes in $1000's\n",
    "'''\n",
    "\n",
    "\n",
    "data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
    "raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
    "data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
    "target = raw_df.values[1::2, 2]\n",
    "\n",
    "\n",
    "df_data = pd.DataFrame(data)\n",
    "\n",
    "list_new_col_names = [\"CRIM\", \"ZN\", \"INDUS\", \"CHAS\", \"NOX\", \"RM\", \"AGE\", \"DIS\", \"RAD\", \"TAX\", \"PTRATIO\", \"B\", \"LSTAT\"]\n",
    "\n",
    "for old_name in list(df_data.columns):\n",
    "    idx = list(df_data.columns).index(old_name)\n",
    "    df_data.rename(columns={old_name : list_new_col_names[idx]}, inplace=True)\n",
    "\n",
    "df_target = pd.DataFrame(target).rename(columns={0:\"MEDV\"})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizando los regresores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we need to normalize the features using mean normalization\n",
    "def norm_data(df_data):\n",
    "    df_data = (df_data - df_data.mean())/df_data.std()\n",
    "\n",
    "    return df_data\n",
    "\n",
    "df_norm_data = norm_data(df_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Planteaminto del problema de regresión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encontrando cantidad de datos nulos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"*\"*10, \"Cantidad de datos nulos en df_data\", \"*\"*10, \"\\n\", df_data.isnull().sum(), \"\\n\", \"*\"*30, \"\\n\")\n",
    "print(\"*\"*10, \"Cantidad de datos nulos en df_target\", \"*\"*10, \"\\n\", df_target.isnull().sum(), \"\\n\", \"*\"*30, \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como no hay datos nulos, no es necesario ajustar el conjunto de datos. Es decir, no es necesario borrar o hacer aproximaciones en registros nulos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encontrando la correlacion entre `target` y `data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr = pd.concat([df_norm_data, df_target], axis=1).corr().round(2)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,7))   \n",
    "sn.heatmap(df_corr, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las variables que mayor correlacion tienen con `MEDV`, son `LSTAT` y `RM`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresión lineal simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para evidenciar la correlación entre las variables, se grafica un diagrama de dispersión. (con los datos regresores normalizados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "\n",
    "features = ['LSTAT', 'RM']\n",
    "\n",
    "for i, col in enumerate(features):\n",
    "    plt.subplot(1, len(features) , i+1)\n",
    "    x = df_norm_data[col]\n",
    "    y = df_target\n",
    "    plt.scatter(x, y, marker='o')\n",
    "    plt.title(f\"MEDV vs {col}\")\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel('MEDV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ones = np.ones((len(data),1))\n",
    "x = df_norm_data[['LSTAT']].values\n",
    "y = df_target[['MEDV']].values\n",
    "A = np.hstack((x,ones))\n",
    "\n",
    "theta = ( pinv(A.T @ A) @ A.T ) @ y\n",
    "h1 = A @ theta\n",
    "\n",
    "# Graficando las variables de interes\n",
    "plt.scatter(df_norm_data['LSTAT'], df_target['MEDV'])\n",
    "plt.xlabel('LSTAT')\n",
    "plt.ylabel('MEDV')\n",
    "plt.plot(x,h1,'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ones = np.ones((len(data),1))\n",
    "x = df_norm_data[['RM']].values\n",
    "y = df_target[['MEDV']].values\n",
    "A = np.hstack((x,ones))\n",
    "\n",
    "theta = ( pinv(A.T @ A) @ A.T ) @ y\n",
    "h2 = A @ theta\n",
    "\n",
    "# Graficando las variables de interes\n",
    "plt.scatter(df_norm_data['RM'], df_target['MEDV'])\n",
    "plt.xlabel('RM')\n",
    "plt.ylabel('MEDV')\n",
    "plt.plot(x,h2,'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresión multivariable normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Cuadratico Medio del modelo lineal : [[21.89483118]]\n"
     ]
    }
   ],
   "source": [
    "ones = np.ones((len(data),1))\n",
    "x = df_norm_data.values\n",
    "y = df_target.values\n",
    "A = np.hstack((x,ones))\n",
    "\n",
    "theta = ( pinv(A.T @ A) @ A.T ) @ y\n",
    "h1 = A @ theta\n",
    "\n",
    "e_1 = (h1-y).T @ (h1-y)/len(x)\n",
    "print(\"Error Cuadratico Medio del modelo lineal :\",e_1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresión multivariable normal y grandiente descendiente: Minimizando la función de costo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = np.zeros([1, len(df_norm_data.columns) + 1 ]) # initialize theta as zeros column vector\n",
    "\n",
    "#gradient descent\n",
    "def gradientDescent(x,y,theta,iters,alpha):\n",
    "    '''\n",
    "    x := normalized independent data variables\n",
    "    y := target or dependent variable\n",
    "    theta := regresors matrix\n",
    "    iters := iterantions\n",
    "    alpha := learning rate\n",
    "    '''\n",
    "    for i in range(iters):\n",
    "        theta = theta - (alpha/len(x)) * np.sum(A * (A @ theta.T - y), axis=0)\n",
    "    \n",
    "    return theta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Cuadratico Medio del modelo gradiente descendiente es : [[21.89483336]]\n"
     ]
    }
   ],
   "source": [
    "theta_GD = gradientDescent(x,y,theta,1000,0.1)\n",
    "h_GD = A @ theta_GD.T\n",
    "\n",
    "e_GD = (h_GD-y).T @ (h_GD-y)/len(x)\n",
    "print(\"Error Cuadratico Medio del modelo gradiente descendiente es :\",e_GD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularización"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matemáticamente, la regularización añade un término que penaliza la complejidad del modelo. En el caso del MSE, tenemos: $$J(\\theta)_{reg} = J(\\theta) + \\alpha R(\\theta), $$ donde $J$:= es la función de costo; $MSE$ := error cuadrático medio; $\\alpha$ := un hiperparàmetro de control y; $C$ := regularizador del modelo.  \n",
    "\n",
    "En la regularización se minimiza la complejidad del modelo y la función de costo. De esta manera, se consigue que el modelo sea más simple y evite el sobreajuste. La minimización sobre la complejidad del modelo se resuelve como un problema de optimización de magnitud. Comunmente se tiene la regularización Ridge, que consiste en optimizar una distancia tipo L1; y la regularización LASSO, que consiste en optimizar una distancia tipo L2. \n",
    "\n",
    "**Ridge: Penalidad L2**\n",
    "El problema a optimizar se plantea como: \n",
    "\n",
    "$$J(\\theta) \\rightarrow min; \\quad s.t. \\quad ||\\theta||^2 \\leq C$$ \n",
    "\n",
    "**LASSO: Penalidad L1** \n",
    "El problema a optimizar se plantea como: \n",
    "$$J(\\theta) \\rightarrow min; \\quad s.t. \\quad ||\\theta||_1 \\leq C$$ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularización Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Cuadratico Medio del modelo lineal : [[22.15852265]]\n"
     ]
    }
   ],
   "source": [
    "ones = np.ones((len(data),1))\n",
    "x = df_norm_data.values\n",
    "y = df_target.values\n",
    "A = np.hstack((x,ones))\n",
    "gamma = 10 # zero gets the same result as normal multivariate regression\n",
    "\n",
    "theta_ridge = ( pinv(A.T @ A + gamma * np.identity(A.shape[1])) @ A.T ) @ y\n",
    "h_ridge = A @ theta_ridge\n",
    "\n",
    "e_ridge = (h_ridge-y).T @ (h_ridge-y)/len(x)\n",
    "print(\"Error Cuadratico Medio del modelo lineal :\",e_ridge)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradiente descendiente y regularización Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = np.zeros([1, len(df_norm_data.columns) + 1 ]) # initialize theta as zeros column vector\n",
    "\n",
    "#gradient descent\n",
    "def gradientDescent(x,y,theta,iters,alpha):\n",
    "    '''\n",
    "    Computes gradient descend. \n",
    "        x := normalized independent data variables\n",
    "        y := target or dependent variable\n",
    "        theta := regresors matrix\n",
    "        iters := iterantions\n",
    "        alpha := learning rate\n",
    "    '''\n",
    "    for i in range(iters):\n",
    "        theta = theta * (1 - alpha * (gamma / len(x))) - (alpha/len(x)) * np.sum(A * (A @ theta.T - y), axis=0)\n",
    "    \n",
    "    return theta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Cuadratico Medio del modelo gradiente descendiente es : [[22.44385979]]\n"
     ]
    }
   ],
   "source": [
    "theta_ridgeGD = gradientDescent(x,y,theta,100,0.1)\n",
    "h_ridgeGD = A @ theta_ridgeGD.T\n",
    "\n",
    "e_ridgeGD = (h_ridgeGD-y).T @ (h_ridgeGD-y)/len(x)\n",
    "print(\"Error Cuadratico Medio del modelo gradiente descendiente es :\",e_ridgeGD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularización LASSO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No tiene solución canónica."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modificando la matriz de regresores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo de orden 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Cuadratico Medio del modelo lineal : [[14.44572524]]\n"
     ]
    }
   ],
   "source": [
    "ones = np.ones((len(x),1))\n",
    "x = df_data.values\n",
    "y = df_target.values\n",
    "A = np.column_stack((x**2,x,ones))\n",
    "theta_2 =( pinv(A.T @ A) @ A.T ) @ y\n",
    "h2 = A @ theta_2\n",
    "\n",
    "e_2 = (h2-y).T @ (h2-y)/len(x)\n",
    "print(\"Error Cuadratico Medio del modelo lineal :\",e_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo de orden 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Cuadratico Medio del modelo lineal : [[19.95321282]]\n"
     ]
    }
   ],
   "source": [
    "ones = np.ones((len(x),1))\n",
    "x = df_data.values\n",
    "y = df_target.values\n",
    "A = np.column_stack((x**3, x**2, x,ones))\n",
    "theta_3 =( pinv(A.T @ A) @ A.T ) @ y\n",
    "h3 = A @ theta_3\n",
    "\n",
    "e_3 = (h3-y).T @ (h3-y)/len(x)\n",
    "print(\"Error Cuadratico Medio del modelo lineal :\",e_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo de orden 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Cuadratico Medio del modelo lineal : [[52.76976999]]\n"
     ]
    }
   ],
   "source": [
    "ones = np.ones((len(x),1))\n",
    "x = df_data.values\n",
    "y = df_target.values\n",
    "A = np.column_stack((x**4, x**3, x**2, x,ones))\n",
    "theta_4 =( pinv(A.T @ A) @ A.T ) @ y\n",
    "h4 = A @ theta_4\n",
    "\n",
    "e_4 = (h4-y).T @ (h4-y)/len(x)\n",
    "print(\"Error Cuadratico Medio del modelo lineal :\",e_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EL mejor modelo, es el de orden 2. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algunas referencias..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive implementation \n",
    "https://medium.com/@siddhantagarwal99/multivariate-linear-regression-in-python-without-scikit-learn-using-normal-equation-bc3ab4334f11\n",
    "\n",
    "https://medium.com/we-are-orb/multivariate-linear-regression-in-python-without-scikit-learn-7091b1d45905"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
